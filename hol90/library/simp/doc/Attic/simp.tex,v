head	1.1;
access;
symbols
	HOL97:1.1.2.6.0.2
	bpHOL97:1.1.2.6
	hol90_9_alpha:1.1.2.1
	hol90_pre8_for_multiple_compilers:1.1.0.2;
locks; strict;
comment	@% @;


1.1
date	96.08.06.12.22.38;	author rjb;	state dead;
branches
	1.1.2.1;
next	;

1.1.2.1
date	96.08.06.12.22.39;	author rjb;	state Exp;
branches;
next	1.1.2.2;

1.1.2.2
date	97.06.02.19.37.40;	author drs1004;	state Exp;
branches;
next	1.1.2.3;

1.1.2.3
date	97.06.02.20.09.31;	author drs1004;	state Exp;
branches;
next	1.1.2.4;

1.1.2.4
date	97.06.03.11.31.17;	author drs1004;	state Exp;
branches;
next	1.1.2.5;

1.1.2.5
date	97.06.03.14.44.19;	author mvi20;	state Exp;
branches;
next	1.1.2.6;

1.1.2.6
date	97.06.03.15.05.32;	author mvi20;	state Exp;
branches
	1.1.2.6.2.1;
next	;

1.1.2.6.2.1
date	97.06.06.12.14.33;	author mvi20;	state Exp;
branches;
next	1.1.2.6.2.2;

1.1.2.6.2.2
date	97.06.13.13.21.53;	author mvi20;	state Exp;
branches;
next	1.1.2.6.2.3;

1.1.2.6.2.3
date	97.07.16.17.09.47;	author mn200;	state Exp;
branches;
next	1.1.2.6.2.4;

1.1.2.6.2.4
date	97.11.14.11.29.23;	author mn200;	state Exp;
branches;
next	;


desc
@@


1.1
log
@file simp.tex was initially added on branch hol90_pre8_for_multiple_compilers.
@
text
@@


1.1.2.1
log
@New library simp.
@
text
@a0 893
\documentstyle[a4]{article}
\bibliographystyle{plain}

\title{A Simplifier/Programmable Grinder for hol90}
\author{Donald Syme}

\include{commands}

\begin{document}
\maketitle
% \tableofcontents

This chapter describes `simplification', which is a 
powerful new proof technique available in the latest version
of \HOL.  

First a word of warning! As always, {\em the more you know about what
an automated tool can do for you, the more effective it will
be for you}. Users should ensure they have
a good understanding of what simplification is
before they make large sale use of it in their poofs.
This will help avoid the plethora of problems
that develop from the misapplication of automated tools.

In particular, users new to theorem proving
systems should probably use simplification sparingly,
until they have a thorough understanding of the basics of how
a theorem proving system works.

This simplifier is capable of doing alot.  However this also
means it is difficult to know exactly what it is doing, or why it stops
working.  Because of this, extensive tracing is possible.

This simplifier is based loosely
on the Isabelle simplifier.
The original motivation for doing this work
was that I was inspired by reading the Isabelle
reference manual (chapter 10) and wanted to see how easy such
a simplifier would be to implement in \HOL.

\section{What is Simplification?}

In its basic form, simplification is a more general
kind of rewriting. Like rewriting, simplification
starts with some term, say $t_1$, and repeatedly applies
a collection of {\it reduction rules} to the term and its
subterms until no more reductions apply.  This produces
the theorem \ml{|- $t_1$ = $t_2$}, which can be utilised
in various ways.  

Simplification is only concerned with the case where the reduction
rules prove that the term $t_1$ is {\it equal} to another term
$t_2$.  Thus the domain of operation of simplification is
most of what is encompassed by {\it equational reasoning}.  
Simplification can be generalized to reduction under preorders, but
for the moment we need only be concerned with the equality case.

\section{Simpsets}

The simplifier needs data to work with.  This is specified in 
{\em simpsets}. Simpsets are an extremely useful way to organize
your work and group theorems together.  You should make it your 
aim to develop good simpsets as part of your theories.
A simpset contains:
\begin{itemize}
    \item A set of rewrite theorems, some of which may be conditional.
    \item A set of congruence theorems which specify
          contextual rewriting information.
    \item A set of conversions which get applied to relevant terms.
    \item A "rewrite maker" function.
\end{itemize}
Simpsets are created in two steps:
\begin{enumerate}
   \item Fragments of simpsets (usually one per theory) are created
using the functions {\tt SIMPSET} or the shortcut {\tt rewrites}.
   \item The fragments are composed (merged) using {\tt mk\_simpset} to
make a simpset, or added to an existing simpset using {\tt add\_to\_ss}.  
\end{enumerate}
This two stage approach makes the implementation of the simplifier
far cleaner.  However, it can be annoying to make large simpsets
by composing smaller fragments when you only want to add a few theorems.
Hence you can use the infix operator \ml{++} to add theorems to
a simpset.  This is useful when you are developing a theory.

For example, the following three methods
are equivalent, except that the first two create
a reusable component {\tt SUMM\_ss}:
\begin{verbatim}
- val SUMM_ss = rewrites [SUMM_DEF,summ_THM];
- val my_ss = mk_simpset [HOL_ss,SUM_ss];

- val SUMM_ss = rewrites [SUMM_DEF,summ_THM];
- val my_ss = hol_ss ++ SUMM_ss;

- val my_ss = hol_ss ++ [SUMM_DEF,summ_THM];
\end{verbatim}

In general you should build simpsets which solve/normalize a
particular class of terms rather than rely on creating simpsets on-the-fly.

\section{An example: List Equality}

The following example shows how to add rewrites to an
existing simpset and apply the simpset to prove simple
results.  The
simpset is made up of simple rewrites about lists, added to the basic
reasoning facilities in {\tt hol\_ss}.
\begin{boxed} \begin{verbatim}
- CONS_11;
val it = |- !h h' t t'. (CONS h t = CONS h' t') = (h = h')

- val my_ss = hol_ss ++ [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS];
- SIMP_CONV my_ss [] (--`[1;2;3] = [1;2;3]`--);
val it = |- ([1;2;3] = [1;2;3]) = T : thm

- SIMP_PROVE my_ss [] (--`~[1;2;3] = [1;2]`--);
val it = |- ~[1;2;3] = [1;2] : thm

- SIMP_PROVE my_ss [] (--`~[1;2;4] = [1;2;3]`--);
val it = |- ~[1;2;4] = [1;2;3] : thm
\end{verbatim} \end{boxed}


\section{Built In Simpsets}

    
Several powerful simpset fragments are included with the core system.
These are based on existing HOL theories.  They can
automate a large amount of ``trivial reasoning'' about
HOL constructs that previously needed special treatment.
\begin{boxed} \begin{verbatim}
   val BOOL_ss : ssdata
   val COMBIN_ss : ssdata
   val LIST_ss : ssdata
   val SUM_ss : ssdata
   val NOT_ss : ssdata
   val PAIR_ss : ssdata
   val UNWIND_ss : ssdata
   val SATISFY_ss : ssdata
   val ARITH_ss : ssdata
\end{verbatim} \end{boxed}
\begin{description}
      \item[{\tt BOOL\_ss}]
            The basic rewrites normally used with {\tt REWRITE\_TAC []}
            plus automatic beta conversion, and a couple of other trivial
            theorems that should have been in the basic rewrites anyway.

      \item[{\tt COMBIN\_ss}]
            Standard theorems about K, S, I, o from the ``combin'' theory.

      \item[{\tt LIST\_ss}]
         The most useful rewrites from the ``list'' library.  Will
         reduce {\tt MAP}, {\tt APPEND}, {\tt EVERY} and so on, 
         where they are applied
         to concrete lists.

      \item[{\tt SUM\_ss}]
         The useful rewrites from the ``sum'' theory, including 
	 conditional rewrites for {\tt INR} and {\tt OUTR}.

      \item[{\tt NOT\_ss}]
         Rewrites for pusing negations inward, and for simplifying 
	disjunctions involving negations.

      \item[{\tt PAIR\_ss}]
            The useful rewrites from the core ``pair'' theory.

      \item[{\tt UNWIND\_ss}]
	    Contains {\tt UNWIND\_FORALL\_CONV} and
	    {\tt UNWIND\_EXISTS\_CONV} for eliminating
	    trivial universal and existential quantifications.

      \item[{\tt SATISFY\_ss}]
	    Does one-level (non-searching) prolog style unification to
	help eliminate obious existential quantifiers.  This is useful
	to help guess unknowns in side conditions.

       \item[{\tt ARITH\_ss}]
This is the most powerful of the built in simpset fragments.  It has
the following features:
\begin{itemize}
    \item {\tt ARITH} is applied as a decision procedure
on all propositions that it may solve.  
    \item This application of {\tt ARITH} is 
``context-aware'', in the sense that any context from the assumption
list (when using {\tt ASM\_SIMP\_TAC}) or that has been collected
via congurence rules (e.g from the left-hand-side of an
implication) which is arithmetic is given to {\tt ARITH\_CONV}
as well.
    \item {\tt ARITH} is also used to collect linear like-terms
together within formulae.  This is implemented via first symbolically
evaluating the formulae with an ML calculator, then using {\tt ARITH\_CONV}
to prove that the original formula equals this result.
    \item Calls to {\tt ARITH} are cached.
\end{itemize}
\end{description}


All of the above objects are {\em simpset fragments}, not simpsets.
Two actual simpsets are premade from these:
\begin{boxed} \begin{verbatim}
   val hol_ss : simpset
   val bool_ss : simpset
\end{verbatim} \end{boxed}
{\tt hol\_ss} is made by combining all of the simpset fragments listed above.
{\tt bool\_ss} contains only {\tt BOOL\_ss} and using 
it is akin to using {\tt REWRITE\_TAC}.


\section{The Simplification Functions}

The basic routines used to invoke simplification are:
\begin{boxed} \begin{verbatim}
    val SIMP_CONV : simpset -> thm list -> conv
    val SIMP_PROVE : simpset -> thm list -> term -> thm
    val SIMP_RULE : simpset -> thm list -> thm -> thm
    val SIMP_TAC : simpset -> thm list -> tactic
    val ASM_SIMP_TAC : simpset -> thm list -> tactic
    val FULL_SIMP_TAC : simpset -> thm list -> tactic
\end{verbatim} \end{boxed}

This section has not yet been written.
See the examples to get a feel for how these work, and try turning
on tracing at various levels.  Also see 
the documentation in the source code.  




\section{Rewrite Rules}

\label{rewrite-rules}

Rewrite rules are theorems which express an equality.  They
are similar to the theorems
provided as input to the `plain' rewriter 
\ml{REWRITE\_TAC}.  Some examples are:
\begin{hol}\begin{verbatim}
   |- !i j k. (i + j) + k = i + (j + k)
   |- HD (CONS h t) = h
   |- NULL [] = T
   |- (!x. t) = t
\end{verbatim}\end{hol}
In each of the rules above, an infinite number of potential
reductions has been specified.  For example the first rule
will act on any term which matches \ml{(--`($i$ + $j$) + $k$`--)}.

Rewrite rules may also be {\em conditional}.  For example:
\begin{hol}\begin{verbatim}
   |- n > 0 ==> (EL n (CONS h t) = EL (n-1) t)
\end{verbatim}\end{hol}
This
rule applies to any term which matches \ml{(--`EL $n$ (CONS $h$ $t$)`--)},
and will only be applied if the condition \ml{(--`$n$ > 0`--)} can be
solved for a particular $n$.  Note that solving an arithmetic side condition
like this automatically will almost certainly 
require a decision procedure to be present.

\subsection{How rewrite rules are made}

Strictly speaking, each reduction rule in a simpset must specify an
equality. However, any theorem which is not already an
equality can be turned into a rewrite rule by simply
converting \ml{|- $t$} to \ml{|- $t$ = T}.  
In fact, the process is a little more complex than this.
All theorems are processed by a {\em rewrite maker}
before being added to a simpset.  The rewrite maker is 
an attribute of the simpset.  The default rewrite maker
performs the following transformations repeatedly:
\begin{itemize}
    \item A conjunction in the final conclusion lead to
    two reduction rules.  Thus
\begin{hol} \begin{verbatim}
       |- ... ==> x /\ y becomes
       |- ... ==> x and
       |- ... ==> y.
\end{verbatim} \end{hol}

    \item Negations \ml{~$t$} in the final conclusion become \ml{$t$ = F}:
    \begin{hol} \begin{verbatim}
       |- ... ==> ~t becomes 
       |- ... ==> (t = F).
\end{verbatim} \end{hol}

    \item Universal quantifiers get stripped off the
    conclusion:
    \begin{hol} \begin{verbatim}
       |- ... ==> !x. t becomes 
       |- ... ==> t.
\end{verbatim} \end{hol}
        
    \item Ignoring conditions, a rewrite rule whose conclusion
    is not an equality, universal quantification,
    negation or conjunction becomes one rewrite rule:
    \begin{hol} \begin{verbatim}
       |- ... ==> x becomes 
       |- ... ==> (x = T).
\end{verbatim} \end{hol}
        
    \item All side conditions are transformed into a single condition,
    where variables free in the condition but not in the equality
    become exisentially quantified.  Thus 
    \begin{hol} \begin{verbatim}
       |- IS_TYPE t ==> PROG x t ==> IS_PROG x becomes
       |- (?t. IS_TYPE t /\ PROG x t) ==> (IS_PROG x = T)
\end{verbatim} \end{hol}
\end{itemize}

Note that in general, some
decision procedure or external routine must be contained in the
simpset in order to automaticaly choose an appropriate value
for these existential variables.  Two routines are provided
in {\tt HOL\_ss} to handle this --- \ml{SATISFY}
and \ml{UNWIND\_EXISTS\_CONV}.  

\subsection{How rewrite rules are applied}

Simplification works by:
\begin{itemize}
    \item Descending the target term in a top-down
fashion.  
    \item At each subterm, the simplifier attempts to match 
the current subterm with one of the rewrite
rules from the simpset.  This is done
efficiently by using term nets to eliminate most
non-matches.  
    \item When a match is found, the simplifier attempts
to solve the conditions to the rewrite rule.  It does this
by trying to simplify the conditions to the term \verb%"T"%.
    \item If the conditions are solved, then the rewrite rule is applied and
the process continues on the new term.  
\end{itemize}

This is a somewhat simplified view of things - the exact term traversal
performed is dictated by the congruence rules being used - this is
explained further in Section~\ref{congruence-rules}.


\subsection{Matching and Higher Order Matching}

For a rewrite rule \ml{|- $c_1$ ==> \ldots ==> $t_1$ = $t_2$},
the simplifier will try to match subterms against $t_1$.  The
matching preformed is a limited version of {\it higher order
matching}.  For many rewrite rules this will have no effect.  However,
wherever function valued variables are free in $t_1$, then higher
order matching may come into play.

Higher order matching allows a pattern such as
\ml{(--`!x. P x`--)} to match a term like \ml{(--`(!x. x = 3)`--)}.  In
this example the variable $P$ will be instantiated to 
\verb%(--`\x. x = 3`--)%.
Higher order matching allows rewrite rules to be far more expressive.
For example, beta reduction can be expressed as a rewrite rule:
\begin{hol} \begin{verbatim}
   |- (\x. P x) y = P y
\end{verbatim} \end{hol}
Some other common higher order rewrite rules are:
\begin{hol} \begin{verbatim}
   |- ~(!x. P x) = (?x. ~P x)
   |- (!x. P x /\ Q) = (!x. P x) /\ Q
   |- (!x. P x /\ Q x) = (!x. P x) /\ (!x. Q x)
\end{verbatim} \end{hol}
All of the quntifier movement conversions from Section~{quantifier-movement}\
can be implemented using higher order rewrite rules.

The limited higher order matching used in the simplifier 
only allows function variables in the match to be paramaterized
by variables which are quantified in the pattern.  Thus \ml{(--`P x`--)}
will not match \ml{(--`x = 3`--)}, whereas \ml{(--`?x. P x`--)} will.
This ensures unique unifiers as the unifiers can be made maximal
over these variables.  This
avoids many of the difficulties that arise with full higher order
matching.  Note, however, that the simplifier 
is sufficiently programmable to allow
other kinds of matching to be used instead of higher order matching.

The higher order matching routines used by the simplifier are also available
for general use by other derived procedures.  The relevant functions
are in the structure {\tt Ho\_match}.


\section{Contextual Rewriting}

The discussion so far has assumed that the simplifier reduces
a term by traversing its subterms in a simple top-depth fashion.  This
is how `plain rewriting' works in the \HOL\ system.  In
this simpe case, reductions
made to subterms are justified by the {\it congruence rules}:
$$\Gamma_1\turn l_1=l_2\qquad\qquad\qquad\Gamma_2\turn r_1=r_2\over
\Gamma\turn l_1\ r_1 = l_2\_r_2$$
$$\Gamma_1\turn t_1=t_2\over
\Gamma\turn (\lquant{x}t_1) = (\lquant{x}t_2)$$
which are in turn implemented by the conversional \ml{SUB\_CONV}.

This process is straight forward to implement, but fails to do justice to the
fact that, when reducing certain subterms, it is desirable 
to make use of additional facts which hold
locally.  These `context theorems' can be used
in the rewrite process, or can be provided as extra input to
local calls to decision procedures.

To take a simple yet important example, consider
the case when reducing the term $t_2$ within \ml{(--`$t_1$ ==> $t_2$`--)}.
It is reasonable to expect that an automatic tool can make use of any rewrite
rules that can be derived from $t_1$ when simplifiying $t_2$.
In other words, $t_1$ is added to the ``current working context'' when
within $t_2$. \footnote{The notion of context turns out to be an important one
in theorem proving work, and provides one of the
motivations for the Window Inference proof style (see the
\HOL\ window inference library for more details on this).
Simplification can be seen as the fully automated, and thus
less controlled, version of window inference, restricted to the equality
relation.}

As an example, consider
the goal \verb%(--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--)%.  The
goal is obviously true, but may require several tactics to solve
in the primitive \HOL\ system.  

The key observation is that when reducing the term on the right of the
implication, the ``theorems'' \ml{|- P x} and \ml{|- ~(x = y)} can
be assumed.  During simplification, they are added as
rewrites to the current simpset.  They are also added to the
working context of any co--operating decision procedures, but that
will be described in more detail later.

To see this in practice, try:
\begin{boxed} \begin{verbatim}
- SIMP_PROVE hol_ss [CONS_11] (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--);
val it = |- ~[1;x;5] = [1;y;5] : thm
\end{verbatim} \end{boxed}


\section{Ordered Rewriting}

\label{ordered-rewriting}

It is well known that some rewrite rules cause `plain rewriting'
(i.e. \ml {REWRITE\_TAC}) to loop, for instance:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
INSERT_SYM |- x INSERT (y INSERT s) = y INSERT (x INSERT s)
\end{verbatim} \end{hol}
Both of these are {\em permutative rewrites}, in the sense that
the right hand side is a permutation of the pattern on the left.

For such rewrites, the simplifier uses the common and
simple solution of only applying these rewrites when the term 
to which they are being applied is strictly reduced according to a term
ordering.  

Ordered rewriting will also work for operations whose
commutative theorems have side
conditions, as for partial functions:
\begin{hol} \begin{verbatim}
PUPDATE_SYM |- ~(x1 = x2) ==>
               (PUPDATE (x1,y1) (PUPDATE (x2,y2) f) = 
                PUPDATE (x2,y2) (PUPDATE (x1,y1) f))
\end{verbatim} \end{hol}

\subsection{AC Rewriting}

The \HOL\ simplifier supports AC rewriting, in the style of the
Isabelle simplifier.  This will create a normalizer for repeated
applications of an associative/comutative operator
like \ml{+}.\footnote{Note that \HOL\ also includes
AC\_CONV for performing similar operations.}

To enable AC ordered rewriting, 
the associative and comutative theorems
for the operation must be inserted in a
simpset using the special function \ml{addac}.
For example, to enable AC rewriting over \ml{+}:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
ADD_ASSOC |- x + (y + z) = (x + y) + z
\end{verbatim} \end{hol}
must be inserted in to a simpset:
\begin{boxed} \begin{verbatim}
- val AC_ADD_ss = pure_ss |> addac (ADD_SYM,ADD_ASSOC)

- SIMP_CONV AC_ADD_ss (--`(y + x) + 3 + 6 + (2 * x + 1)`--)
val it = |- (y + x) + 3 + 6 + (2 * x + 1) =
            1 + 3 + 6 + y + x + 2 * x : thm

- SIMP_CONV AC_ADD_ss (--`x + 3 + y + 2 * x + 6 + 1`--)
val it = |- x + 3 + y + 2 * x + 6 + 1 =
            1 + 3 + 6 + y + x + 2 * x : thm

- SIMP_PROVE AC_ADD_ss (--`(y + x) + 3 + 6 + (2 * x + 1) =
                           x + 3 + y + 2 * x + 6 + 1`--)
val it = |- (y + x) + 3 + 6 + (2 * x + 1) =
            x + 3 + y + 2 * x + 6 + 1 : thm
\end{verbatim} \end{boxed}


This is implemented using ordered rewriting, with a term ordering that
is AC compatible.  
The function \ml{addac} is a simple interface to \ml{addrewrs}.  Three
rewrite rules are needed to implement AC rewriting:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
GSYM ADD_ASSOC |- (x + y) + z = x + (y + z)
ADD_LASSOC |- x + (y + z) = y + (x + z)
\end{verbatim} \end{hol}
The function \ml{addac} derives the third of these from the first two.
Also, note that the standard form for \HOL\ associativity theorems is the
wrong way round for the purposes of normalizing AC nestings to
the right --- \ml{addac} reverses this automatically.


\section{Tracing}

Simplification often involves many, many inferences, and complex
paths of deduction may occur, leading to almost magical results.
There is a down side to this - simplification is difficult
to understand, and even more difficult to debug when things
go wrong.

The value provided to control tracing is:
\begin{boxed} \begin{verbatim}
   val trace_level : int ref
\end{verbatim} \end{boxed}
The trace levels currently range from 0 to 5, where level
0 is no tracing and level 5 presents enormous quantities of information.
The aim has been to make trace level 1 produce sufficient information
to debug most problems.  Trace levels 3 to 5 should only be needed
when debugging the simplifier itself.



\section{Decision Procedures and Simplification}

It is exceptionally useful to allow the integration
{\it decision procedures} with the simplification process,
particularly arithmetic decision procedures.

In the context of this discussion, a decision procedure is a function which
performs complex computation before producing a reduction for
a term.  The example we shall use is \ml{ARITH}, 
which determines the truth of linear
arithmetic formulae over the natural numbers.
It is easy to imagine decision procedures for other
domains such as the integer and real numbers.

Decision procedures are integrated into the simplification
process by adding them to simpsets.  They get
invoked at low priority, in the sense that all reductions via
rewrite rules are performed before trying the 
procedure on a term.  All
decision procedures are invoked for every reducable subterm.  

See the examples in the source code for how 
to add a decision procedure to a simpset.

\section{Congruence Rules}

\label{congruence-rules}

We now fill in the details of the general
process we have outlined above.  During simplification, facts
get added to the current working context because of the application
of {\em congruence rules}.  The user is encouraged to learn to recognise
when a certain construct allows additional crucial assumptions
to be made when simplifiying subterms, and to learn how
to express this fact by a congruence rule.

Congruence rules are contained within simpsets.  User congruence
rules are usually theorems, although congruence rules may also
be ML functions (these are potentially useful for infinite families
of congruence rules, and are used for highly speed
critical congruence rules such as those for equality).  


\subsection{Constructing Congruence Rules}

Some sample congruence rules are:
\begin{hol} \begin{verbatim}
COND_CONG |- (g = g') ==>
             (g'  ==> (t = t')) ==>
             (~g' ==> (e = e')) ==>
             ((g => t | e) = (g' => t' | e'))

RES_FORALL_CONG |- (R = R') ==>
                   (!x. R' x ==> (P x = P' x)) ==>
                   ((!x::R. P x) = (!x::R'. P' x))
\end{verbatim} \end{hol}
These theorems are not hard to prove.
The principal difficulty is in {\it formulating} the rules
in the first place.  The simplifier only accepts 
congruence rules formulated in a certain way.   
We shall examine the process of formulating
the first congrunce rule in some detail.

The purpose of a congruence rule is to state how
a certain contruct is simplified by simplifying its
subterms.  The place to begin is with a `template'
of the construct to be simplified.  In this
case we are interested in simplifying conditionals, thus
the template is \ml{(--`$g$ => $t$ | $e$`--)}.  

Next, the final conclusion of the congruence rule
must state that the free subterms $g$, $t$ and $e$ get simplified, and
that the term produced is equal to the term we started with.
Thus the final conclusion is
\begin{hol} \begin{verbatim}
COND_CONG |- ... ==>
             ((g => t | e) = (g' => t' | e'))

\end{verbatim} \end{hol}
Next, the antecedents to this final conclusion specify how these
variables are related.  They are
interpreted as instructions by the simplifier about the order
in which the subterms should be simplified, and what context assumptions may be
made for each subterm.
The first antecedent is simple enough: $g = g'$.  The simplifier
interprets this as ``first starting with $g$, simplify it and get a new
$g'$''.  The second is more complex: \ml{$g'$ ==> ($t$ = $t'$)}.
This is interpreted as ``simplify $t$ to some $t'$, adding the
fact $g'$ to the current context''.  In other words, the antecedent
says that it is valid to assume $g'$ when simplifying $t$.
The third antecedent is similar: \ml{~$g$ ==> ($e$ = $e'$)}.  This
allows the introduction of the context assumption \ml{~$g$}.

After all three antecedents have been processed and discharged by
the simplifier, a theorem {\tt |- ($g$ => $t$ | $e$) = ($g'$ => $t'$ | $e'$}
will have been produced, where the values for $g'$, $t'$ and $e'$ have
been discovered by contextual simpification.  This theorem is
then used by the simplifier to help reduce the entire term.

Putting all this together gives the general congruence rule:
\begin{hol} \begin{verbatim}
COND_CONG |- (g = g') ==>
             (g'  ==> (t = t')) ==>
             (~g' ==> (e = e')) ==>
             ((g => t | e) = (g' => t' | e'))
\end{verbatim} \end{hol}

\subsection{Bad congruence rules}

Ill-formed congruence rules will cause unpredictable and incorrect
behaviour.  The user should study examples of congruence rules,
consult the relevant manual sections and communicate with other
\HOL\ users should this be a problem.



\section{Avoiding the Pitfalls of Simplification}

Simplification is a powerful theorem proving technique, but is
prone to several major problems.  
This section is designed to make the user aware of these in advance!

The pitfalls of simplification can generally be
avoided by two techniques:
\begin{itemize}
   \item Using well designed simpsets.
   \item Using tracing extensively.
\end{itemize}
The behaviour of simplification is almost totally dependent on the
simpset being used.  The user should stop and think about
exactly what reduction behavior they are specifying when they
group together certain theorems, conversions and decision
procedures.  A well designed simpset will work on a particular
class of problems, and in many cases will do a thorough job
of proving simple facts within that domain.  A poorly
designed simpset constructed by throwing together random
theorems will create all sorts of problems at a later date.

\subsection{Non-termination}

Simplification will continue until no more reductions apply.  It is very
easy to create simpsets which will result in non-termination when
applied to some terms.  \HOL\ detects some simple cases of
non-terminating rewrites (e.g. it doesn't admit rewrites like
\ml{|- x = I x} since the pattern on the left occurs within the
right).  However, there is no general protection against this.
Generally problems arise when two or more theorems interact
to produce looping, such as \ml{|- x > y = y < x} and
\ml{y < x = x > y}.

The best way to avoid non-termination is to ask
the following question about each rewrite you place in a simpset:
{\it Is the rewrite actually contributing toward bringing terms
toward a particular normal form}.  For example, the rewrite
\ml{|- x > y = y < x} should only be added to a simpset if
the normal form we are heading for involves only instances of \ml{<}
for all linear inequalities.

\subsection{Backward Chaining}

Conditional rewriting allows a limited degree of search when 
rewriting, since the rewrite is not applied unless all conditions
are solved.  The simplifier itself is used to solve these
conditions.  This will often lead to looping if
theorems which contain the pattern within the conditions
are added as rewrite rules.  The most obvious example is
transitivity theorems:
\begin{hol} \begin{verbatim}
    |- (?z. x < z /\ z < y) ==> x < y
\end{verbatim} \end{hol}
Do not put these theorems into simpsets!

\subsection{Non-confluence}

When faced with a choice of two rewrite rules, both of which are 
applicable to a given term, the simplifier will choose
one and ignore the other.  This can lead to {\em confluence}
problems, i.e. it may be that a different final result will
be produced depending on the order in which rewrites are applied.
Non-confluence is mainly a problem for the long term maintainability
of proofs.

Some simpsets may be confluent regardless of the presence of
conflicting rewrite rules.  An extensive literature exists
on term rewriting system and their properties such as 
termination and confluence, which the user is encouraged to
study if the subject proves particularly important.

An example of non-confluence is given by the rewrites:
\begin{hol} \begin{verbatim}
<example>
\end{verbatim} \end{hol}

\subsection{Over-applicability}

Consider the following potential rewrite rule, taken from 
the underlying theory for the abstract theory of groups:
\begin{hol} \begin{verbatim}
    |- (?G. GROUP (G,prod) /\ G x /\ G y /\ G z) ==>
       (prod (prod x y) z = prod x (prod y z))
\end{verbatim} \end{hol}
The theorem simply states that if $G$ and $prod$ are
together define a algebraic group, then $prod$ is associative.
Note there are no constants apart from \ml{GROUP} --- $G$ and
$prod$ are variables.

The problem with such a rewrite rule is that the pattern 
\ml{(--`prod (prod x y) z`--)} will produce many undesireable matches.
The problem is that the rewrite rule is over applicable.  The
best solution at the moment is to make the intent of the rule
more clear, by replacing \ml{(--`prod`--)} with a function
to compute \ml{(--`prod`--)} for a given group:
\begin{hol} \begin{verbatim}
    |- GROUP (G,prod) /\ G x /\ G y /\ G z ==>
       (PROD (G,prod) (PROD (G,prod) x y) z = 
        PROD (G,prod) x (PROD (G,prod) y z))
\end{verbatim} \end{hol}
The pattern \ml{(--`PROD (G,prod) (PROD (G,prod) x y) z`--)} will
now be suitably applicable.  The use of \ml{PROD} may seem
redundant, but turns out to be a suitable generalization.



\section{Summary}

To summarize the main points of this document:
\begin{itemize}
    \item A powerful contextual, conditional simplifier is available
    through the functions \ml{SIMP\_CONV}, \ml{SIMP\_RULE},
    \ml{SIMP\_TAC}, \ml{ASM\_SIMP\_TAC} etc.
    \item Rewrite rules are organised in objects called {\it simpsets}.
    The best simpsets are generally created by making small simpsets and
    combining them with other simpset fragments to form powerful tools.
    \item Rewrite rules are applied using a limited form of higher
    order matching.  Higher order matching allows general theorems about
    functionals such as quantifiers to be applied without the use
    of purpose built conversions.
    \item Simpsets may also contain congruence rules.  Congruence
    rules dictate the term traversal strategy used during simplification
    and the cause the production of context theorems
    \item Simpsets may contain conversions which can act as infinite sets
    of rewrite rules.  This is useful for conversion schemas
    which are essentially reduction but which cannot be formulated
    as rewrite rules (e.g. \ml{REDUCE\_CONV}).
    \item Simpsets may contain decision procedures.  These are invoked
    at lowest priority, and have access to the current working
    context.  The arithmetic decision procedure included with
    \ml{arith\_ss} is an example of the use of this.
\end{itemize}

\section{An extended example}

\begin{verbatim}

val summ_DEF = new_recursive_definition {  
    def=(--`(summ f 0 = 0) /\
        (summ f (SUC n) = f n + summ f n)`--),  
    fixity=Prefix,  
    name="summ_DEF",  
    rec_axiom=theorem "prim_rec" "num_Axiom"  };

(* now define the normal notion of summation *)

val SUMM_DEF = new_definition("SUMM_DEF",
    (--`SUMM f n m = summ (\k. f(n+k)) ((m+1)-n)`--));

(* The following is the actual way we wnat to define this - we could do this *)
(* with TFL *)

val summ = mk_thm([],
    (--`(!f. summ f 0 = 0) /\
        (!f n. n > 0 ==> (summ f n = f 0 + (summ (\k. f (k+1)) (n-1))))`--));

         
val SUMM_0 = prove((--`!f n m. (n = m + 1) ==> (SUMM f n m = 0)`--),
    SIMP_TAC hol_ss [summ,SUMM_DEF]
);
val SUMM_1 = prove((--`!f n m. (n = m) ==> (SUMM f n m = f n)`--),
    SIMP_TAC hol_ss [summ,SUMM_DEF]
);
val SUMM_TAKE_LEFT = prove(
    (--`!f n m. (n < m) ==> (SUMM f n m = f n + SUMM f (n+1) m)`--),
    SIMP_TAC hol_ss [SUMM_DEF,summ]
);

(* this can also be proved - don't have time to do it now *)
val SUMM_TAKE_RIGHT = mk_thm([],
    (--`!f n m. (n < m) ==> (SUMM f n m = SUMM f n (m-1) + f m)`--)
);


(* sum from left - much more efficient as it uses addition not subtraction *)
val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = hol_ss ++ SUMML_ss;

val SUMMR_ss = rewrites [SUMM_TAKE_RIGHT, SUMM_1,SUMM_0];
val summr_ss = hol_ss ++ SUMMR_ss;


(*-------------------------------------------------------------------------
 * SUMM_x = |- !n. n >= 1 ==> (2 * SUMM (\x. x) 1 n = (n + 1) * n) : thm
 *-----------------------------------------------------------------------*)

add_theory_to_sml "arithmetic";;

val SUMM_x = prove(
    (--`!n. n >= 1 ==> (2*(SUMM (\x.x) 1 n) = (n + 1) * n)`--),
    INDUCT_TAC
    THENL [
       FULL_SIMP_TAC summr_ss [],
       ASM_CASES_TAC (--`n=0`--) THEN 
       ASM_SIMP_TAC summr_ss [LEFT_ADD_DISTRIB,RIGHT_ADD_DISTRIB]
    ]
);


(*------------------------------------------------------------------------- 
 * Using SIMP_CONV as a calculator for Sum
 *-----------------------------------------------------------------------*)

delete_arith_caches();
profile (SIMP_CONV summl_ss []) (--`2 * SUMM (\x. x) 1 10`--);
(* Total runtime: 1.550155 *)
profile (SIMP_CONV summl_ss []) (--`2 * SUMM (\x. x) 1 15`--);
(* Total runtime: 3.430343 *)
profile (SIMP_CONV summl_ss []) (--`2 * SUMM (\x. x) 1 20`--);
TkHol - (* Total runtime: 5.890589 *)
profile (SIMP_CONV summl_ss []) (--`2 * SUMM (\x. x) 1 30`--);
(* Total runtime: 13.081308 *)
profile (SIMP_CONV summl_ss []) (--`2 * SUMM (\x. x) 1 40`--);


profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*x*x) 1 2`--);
(* Total runtime: 0.160016 *)
profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*x*x) 1 3`--);
TkHol - (* Total runtime: 0.620062 *)
profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*x*x) 1 4`--);
TkHol - (* Total runtime: 1.660166 *)
profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*x*x) 1 5`--);
TkHol - (* Total runtime: 3.680368 *)
profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*x*x) 1 6`--);
TkHol - (* Total runtime: 7.270727 *)
profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*x*x) 1 7`--);
TkHol - (* Total runtime: 12.841284 *)

profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*y*y) 1 3`--);
(* Total runtime: 0.720072 *)
val it = |- SUMM (\x. x * y * y) 1 3 = 6 * y * y : thm
profile (SIMP_CONV summl_ss []) (--`SUMM (\x. x*y*y) 1 10`--);
(* Total runtime: 5.220522 *)
val it = |- SUMM (\x. x * y * y) 1 10 = 55 * y * y : thm


(*------------------------------------------------------------------------- 
 *
 *-----------------------------------------------------------------------*)


\end{verbatim}


\end{document}
@


1.1.2.2
log
@blah
@
text
@d95 1
a95 1
- val my_ss = hol_ss ++ rewrites [SUMM_DEF,summ_THM];
@


1.1.2.3
log
@fixes to documentation so examples actually run.
@
text
@d87 1
a87 2
a reusable component {\tt SUMM\_ss}.
The example is taken from the longer example at the end of this chapter.
d89 1
a89 1
- val SUMM_ss = rewrites [SUMM_DEF,summ_DEF];
d92 1
a92 1
- val SUMM_ss = rewrites [SUMM_DEF,summ_DEF];
d95 1
a95 1
- val my_ss = hol_ss ++ rewrites [SUMM_DEF,summ_DEF];
d97 1
d107 1
a107 4
reasoning facilities in {\tt bool\_ss}.  The final line indicates that
these rewrites are actually already present in the built-in simpset {\tt hol\_ss},
which should be your default starting point when creating new simpsets.
{\tt hol\_ss} contains powerful arithmetic reasoning simplification strategies.
a108 2
- add_theory_to_sml "list";
...
d112 2
a113 1
- SIMP_CONV bool_ss [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS] ``[1;2;3] = [1;2;3]``;
d116 2
a117 8
- SIMP_CONV bool_ss [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS] ``[x;y] = [1;2]``;
val it = |- ([x; y] = [1; 2]) = (x = 1) /\ (y = 2) : thm

- val silly_ss = bool_ss ++ rewrites [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS];
val silly_ss = - : simpset

- SIMP_CONV silly_ss [] ``[x;y] = [1;2]``;
val it = |- ([x; y] = [1; 2]) = (x = 1) /\ (y = 2) : thm
d119 1
a119 1
- SIMP_PROVE hol_ss [] ``~([1;2;4] = [1;2;3])``;
a120 20

\end{verbatim} \end{boxed}
Here is the trace produced when tracing is turned on at a low level:
\begin{boxed} \begin{verbatim}
- open Trace;
- trace_level := 1;;

-  SIMP_PROVE hol_ss [] ``~([1;2;4] = [1;2;3])``;
  rewriting [1; 2; 4] = [1; 2; 3] with |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  rewriting 1 = 1 with |- (x = x) = T
  rewriting [2; 4] = [2; 3] with |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  rewriting 2 = 2 with |- (x = x) = T
  rewriting [4] = [3] with |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  4 = 3 via cache hit! simplifies to: F
  rewriting [] = [] with |- (x = x) = T
  rewriting F /\ T with |- F /\ t = F
  rewriting T /\ F with |- T /\ t = t
  rewriting T /\ F with |- T /\ t = t
  rewriting ~F with |- ~F = T
val it = |- ~([1; 2; 4] = [1; 2; 3]) : thm
d205 1
a205 2
{\tt hol\_ss} is made by combining all of the simpset fragments listed above.  This
is what most users will initially use.
d250 1
a250 1
EL_CONS |- n > 0 ==> (EL n (CONS h t) = EL (n-1) t)
d472 1
a472 2
simpset by making a \ml{ssdata} object and merging it with 
an existing simpset.
d480 1
a480 3
- val ac_ss = pure_ss ++ SIMPSET {ac =[(ADD_SYM,ADD_ASSOC)],
                                      convs=[],dprocs=[],filter=NONE,rewrs=[],
                                      congs=[]};
d482 1
a482 1
- SIMP_CONV ac_ss ``(y + x) + 3 + 6 + (2 * x + 1)``;
d486 1
a486 1
- SIMP_CONV ac_ss ``x + 3 + y + 2 * x + 6 + 1``;
d490 2
a491 2
- SIMP_PROVE ac_ss ``(y + x) + 3 + 6 + (2 * x + 1) =
                           x + 3 + y + 2 * x + 6 + 1``;
d522 1
a522 1
   val Trace.trace_level : int ref
a785 5
new_theory "summ";
infix ++;
open Trace;
trace_level := 1;;

d798 3
a800 2
(* The following is the actual way we want to define this - we could do this *)
(* with TFL.  For now we'll just axiomatize it. *)
d817 1
a817 2
(* this can also be proved, but simplification doesn't help to do it *)
(* so we'll assume it for now *)
d849 1
a849 1
 * Using SIMP_CONV as a calculator for Sums
d852 31
a882 17
clear_arith_caches();
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 10`--);
SIMP_CONV summr_ss [] (--`2 * SUMM (\x. x) 1 10`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 15`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 20`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 30`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 40`--);


SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 2`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 3`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 4`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 5`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 6`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 7`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*y*y) 1 3`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*y*y) 1 10`--);
@


1.1.2.4
log
@blah
@
text
@d77 1
a77 1
make a simpset, or added to an existing simpset using {\tt ++}.  
d513 2
a514 2
                                  convs=[],dprocs=[],filter=NONE,rewrs=[],
                                  congs=[]};
d532 2
a533 1
is AC compatible.    Three
d540 1
a540 1
The simplifier derives the third of these from the first two.
d675 1
a675 2
Ill-formed congruence rules (i.e. congruence rules
not in the form specified above) will cause unpredictable and incorrect
@


1.1.2.5
log
@Myra's first little change, more to come!
@
text
@d253 1
a253 1
This section is being written by Myra.
@


1.1.2.6
log
@Myra is doing this insignificant update at Michael's request.
@
text
@d253 1
a253 1
This section is being written by Myra right now!
@


1.1.2.6.2.1
log
@Fixed AC rewriting bug, by Don after Myra found the bug.

Fixed documentation to reflect this.
@
text
@d501 1
a501 1
the associativity and commutativity theorems
d507 1
a508 1
ADD_SYM |- x + y = y + x
d510 1
a510 6
must be inserted in to a simpset:\footnote{Note that
the theorem \ml{ADD\_SYM} is misnamed in \HOL.  It refers
to the comutativity of addition, and so should be called
\ml{ADD\_COMM}.  
Symmetry is a notion
that should only be used for relations such as \verb!=!.}
d512 1
a512 1
- val ac_ss = pure_ss ++ SIMPSET {ac =[(ADD_ASSOC,ADD_SYM)],
d537 1
a537 1
ADD_LCOMM |- x + (y + z) = y + (x + z)
d542 1
a542 1
the right --- the simplifier reverses this automatically.
@


1.1.2.6.2.2
log
@Fixes to simplifier documentation by Myra VanInwegen. Mostly added examples.
@
text
@d5 1
a5 2
\author{Donald Syme\thanks{Myra VanInwegen provided additional
material.}}
a6 3
% ask Don how to fix the code so that people don't have to say 
% ``infix ++''

d15 1
a15 1
of \HOL. 
d21 1
a21 1
before they make large sale use of it in their proofs.
d55 1
a55 1
Simplification can be generalised to reduction under preorders, but
d61 1
a61 1
{\em simpsets}. Simpsets are an extremely useful way to organise
d79 5
a83 8
This two stage approach makes the implementation of the simplifier far
cleaner.  However, it can be annoying to make large simpsets by
composing smaller fragments when you only want to add a few theorems.
Hence you can use the infix\footnote{At least it is intended that
\ml{++} be infix. Currently it isn't when you start up HOL, so you
must type \ml{infix ++} to make it so.} operator \ml{++} to add
theorems to a simpset.  This is useful when you are developing a
theory.
d90 2
a91 2
val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = mk_simpset [HOL_ss, SUMML_ss];
d93 2
a94 2
val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = hol_ss ++ SUMML_ss;
d96 1
a96 1
val summl_ss = hol_ss ++ rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
d98 1
a98 1
In general you should build simpsets which solve/normalise a
d103 8
a110 8
The following example shows how to add rewrites to an existing simpset
and apply the simpset to prove simple results.  The simpset is made up
of simple rewrites about lists, added to the basic reasoning
facilities in {\tt bool\_ss}.  The final line indicates that these
rewrites are actually already present in the built-in simpset {\tt
hol\_ss}, which should be your default starting point when creating
new simpsets.  {\tt hol\_ss} contains powerful arithmetic reasoning
simplification strategies.
d117 1
a117 2
- SIMP_CONV bool_ss [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS] 
  ``[1;2;3] = [1;2;3]``;
d120 1
a120 1
- SIMP_CONV bool_ss [CONS_11,NOT_CONS_NIL,NOT_NIL_CONS] ``[x;y] = [1;2]``;
d139 1
a139 2
  rewriting [1; 2; 4] = [1; 2; 3] with 
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
d141 1
a141 2
  rewriting [2; 4] = [2; 3] with 
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
d143 1
a143 2
  rewriting [4] = [3] with 
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
d192 1
a192 1
         Rewrites for pushing negations inward, and for simplifying 
d205 1
a205 1
	help eliminate obvious existential quantifiers.  This is useful
d217 1
a217 1
via congruence rules (e.g from the left-hand-side of an
d253 4
a256 27
In the examples below the theorems and definitions come from the
theories ``List'' and ``arithmetic'' except where noted.

\ml{SIMP\_CONV} makes a simplification conversion from the given
simpset.  The theorems in the second argument are used as additional
rewrites. The conversion uses a top-depth strategy for rewriting. It
sets both the solver and the depther to be \ml{SIMP\_CONV} itself. 
\ml{SIMP\_CONV} never fails, though it may diverge.  Beware of
divergence when trying to solve conditions to conditional rewrites.
Examples of its use are:
\begin{verbatim}
- SIMP_CONV hol_ss [] (--`TL[SUC 0;1 + 4; 2 * (3 + 2) + m]`--);
val it = |- TL [SUC 0; 1 + 4; 2 * (3 + 2) + m] = [5; m + 10] : thm
- SIMP_CONV hol_ss [LEFT_ADD_DISTRIB] (--`2 * (b + c) + a`--);
val it = |- 2 * (b + c) + a = a + 2 * b + 2 * c : thm
- SIMP_CONV hol_ss [] (--`(b + c + a) + d = (a + b) + (c + d)`--);
val it = |- ((b + c + a) + d = (a + b) + c + d) = T : thm
\end{verbatim}

\ml{SIMP\_PROVE} invokes \ml{SIMP\_CONV} and then strips off the 
\ml{= T} at the end of the theorem. For example:
\begin{verbatim}
- SIMP_PROVE hol_ss [] (--`(b + c + a) + d = (a + b) + (c + d)`--);
val it = |- (b + c + a) + d = (a + b) + c + d : thm
- SIMP_PROVE hol_ss [] (--`!m n p. (p + m = p + n) = (m = n)`--);
val it = |- !m n p. (p + m = p + n) = m = n : thm
\end{verbatim}
a257 27
\ml{SIMP\_RULE} invokes \ml{CONV\_RULE} with the conversion generated
by \ml{SIMP\_CONV} using the given simpset and additional rewrites. For
example:
\begin{verbatim}
- val th = SPEC (--`CONS (h:'a) t`--) LENGTH_BUTLAST;
val th =
  |- ~(CONS h t = []) ==>
     (LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH (CONS h t))) : thm
- SIMP_RULE hol_ss [] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH t + 1) : thm
\end{verbatim}
Now, we would like to end up with \ml{LENGTH t} on the right hand side
instead of \ml{PRE (LENGTH t + 1)}. We could try the following:
\begin{verbatim}
- SIMP_RULE hol_ss [PRE] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH t + 1) : thm
\end{verbatim}
However, this doesn't work: the rules in \ml{hol\_ss} rewrite \ml{SUC n} to
\ml{n + 1}, and \ml{PRE} only works on \ml{SUC n}. One solution is to
create a simpset that doesn't include the arithmetic simplification:
\begin{verbatim}
val list_ss = mk_simpset [BOOL_ss, COMBIN_ss, LIST_ss, SUM_ss, NOT_ss,
			  PAIR_ss, UNWIND_ss, SATISFY_ss];
= val list_ss = - : simpset
- SIMP_RULE list_ss [PRE] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = LENGTH t : thm
\end{verbatim}
a258 22
\ml{SIMP\_TAC} makes a simplification tactic from the given simpset
and additional rewrite theorems. The tactic uses a top-depth strategy
for rewriting, and will be recursively reapplied when a simplification
step makes a change. Basically, it invokes \ml{CONV\_TAC} with the
conversion generated by \ml{SIMP\_CONV} using the given simpset and
additional rewrites. Here is an example of using \ml{SIMP\_TAC} (the
definitions are given below in Section \ref{extended-example}):
\begin{verbatim}
- set_goal ([], --`!f n. (SUMM f n n = f n)`--);
val it =
  Status: 1 proof.
  1. Incomplete:
       Initial goal:
       ``!f n. SUMM f n n = f n``
   : proofs
- e (SIMP_TAC hol_ss [summ_DEF,SUMM_DEF]);
OK..
1 subgoal:
val it =
  ``!f n. summ (\k. f (k + n)) 1 = f n``
   : goalstack
\end{verbatim}
a259 9
\ml{ASM\_SIMP\_TAC} takes the terms in the assumption list,
\ml{ASSUME}s them, and adds them to the list of theorems used for
rewriting. The assumptions are also added to the context that will be
passed to conversions.

\ml{FULL\_SIMP\_TAC} simplifies the assumptions one by one, before
simplifying the goal.  The assumptions are simplified in the order
that they are found in the assumption list, and the simplification
of each assumption is used when simplifying the next assumption.
a289 22
A bit of care has to be taken when formulating conditional rewrites.
For example, say we want to use the fact that the function {\tt MAP2}
preserves the length of lists. One possible way to phrasing the
theorem is 
\begin{hol} \begin{verbatim}
MY_LENGTH_MAP2 |- !f m l1 l2. (LENGTH l1 = m) /\ (LENGTH l2 = m) ==>
                  (LENGTH (MAP2 f l1 l2) = m)
\end{verbatim} \end{hol}

However, this will not work as a congruence rule. In a proper rewrite
rule, the variables in the right hand side of the consequent must be
contained in the variables on the left hand side. It is not sufficient
that the values can be determined by the conditions. Thus the rule
must be reformulated, for example as:
\begin{hol} \begin{verbatim} 
LENGTH_MAP2 |- !l1 l2.
               (LENGTH l1 = LENGTH l2) ==>
               (!f. (LENGTH (MAP2 f l1 l2) = LENGTH l1) /\
                    (LENGTH (MAP2 f l1 l2) = LENGTH l2))
\end{verbatim} \end{hol}


d333 1
a333 1
    become existentially quantified.  Thus 
d340 6
a345 5
Note that in general, some decision procedure or external routine must
be contained in the simpset in order to automatically choose an
appropriate value for these existential variables.  Two routines are
provided in {\tt HOL\_ss} to handle this --- \ml{SATISFY} and
\ml{UNWIND\_EXISTS\_CONV}.
d374 1
a374 1
matching performed is a limited version of {\it higher order
d394 1
a394 1
All of the quantifier movement conversions from Section~{quantifier-movement}\
d398 1
a398 1
only allows function variables in the match to be parameterised
d418 1
a418 1
this simple case, reductions
d436 1
a436 1
rules that can be derived from $t_1$ when simplifying $t_2$.
d446 2
a447 4
As an example, consider the goal 
\begin{verbatim}
       (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--)
\end{verbatim}
d460 1
a460 2
- SIMP_PROVE hol_ss [CONS_11] 
  (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--);
d494 5
a498 5
The \HOL\ simplifier supports AC (associative/commutative) rewriting,
in the style of the Isabelle simplifier.  This will create a
normaliser for repeated applications of an associative/commutative
operator like \ml{+}.\footnote{Note that \HOL\ also includes AC\_CONV
for performing similar operations.}
d512 1
a512 1
to the commutativity of addition, and so should be called
d546 1
a546 1
wrong way round for the purposes of normalising AC nestings to
d589 1
a589 1
decision procedures are invoked for every reducible subterm.  
d603 1
a603 1
to be made when simplifying subterms, and to learn how
d631 1
a631 1
the first congruence rule in some detail.
d634 1
a634 1
a certain construct is simplified by simplifying its
d666 1
a666 1
been discovered by contextual simplification.  This theorem is
d686 1
d701 1
a701 1
exactly what reduction behaviour they are specifying when they
d778 1
a778 1
\ml{(--`prod (prod x y) z`--)} will produce many undesirable matches.
d790 2
a791 1
redundant, but turns out to be a suitable generalisation.
d793 1
d796 1
a796 1
To summarise the main points of this document:
a821 1
\label{extended-example}
d828 1
a828 1
trace_level := 1;
d843 1
a843 1
(* with TFL.  For now we'll just axiomatise it. *)
d850 2
a851 1
    SIMP_TAC hol_ss [summ,SUMM_DEF]);
d853 2
a854 1
    SIMP_TAC hol_ss [summ,SUMM_DEF]);
d857 8
a864 1
    SIMP_TAC hol_ss [SUMM_DEF,summ]);
a865 12
(* here's an example of using SIMP_TAC several times along with 
   small helper theorems *)
local
    val thm = SIMP_PROVE hol_ss [] 
	(--`(n < m) ==> ((m + 1) - n = SUC (m - n))`--)
in
val SUMM_TAKE_RIGHT = TAC_PROOF
    (([], --`!f n m. (n < m) ==> (SUMM f n m = SUMM f n (m-1) + f m)`--),
     SIMP_TAC hol_ss [SUMM_DEF, summ_DEF] THEN
     SIMP_TAC bool_ss [thm, summ_DEF] THEN 
     SIMP_TAC hol_ss [summ_DEF])
end;
d879 1
a879 1
add_theory_to_sml "arithmetic";
d888 2
a889 1
    ]);
d913 7
d922 1
@


1.1.2.6.2.3
log
@Documentation updated to reflect addition of CONG_ss to Simpsets.{sig,sml}
@
text
@d8 1
a8 1
% ask Don how to fix the code so that people don't have to say
d17 1
a17 1
This chapter describes `simplification', which is a
d19 1
a19 1
of \HOL.
d22 11
a32 9
  an automated tool can do for you, the more effective it will be for
  you}. Users should ensure they have a good understanding of what
simplification is before they make large sale use of it in their
proofs.  This will help avoid the plethora of problems that develop
from the misapplication of automated tools.

In particular, users new to theorem proving systems should probably
use simplification sparingly, until they have a thorough understanding
of the basics of how a theorem proving system works.
d34 2
a35 2
This simplifier is capable of doing a lot.  However this also means it
is difficult to know exactly what it is doing, or why it stops
d38 6
a43 4
This simplifier is based loosely on the Isabelle simplifier.  The
original motivation for doing this work was that I was inspired by
reading the Isabelle reference manual (chapter 10) and wanted to see
how easy such a simplifier would be to implement in \HOL.
d53 1
a53 1
in various ways.
d58 1
a58 1
most of what is encompassed by {\it equational reasoning}.
d64 1
a64 1
The simplifier needs data to work with.  This is specified in
d66 1
a66 1
your work and group theorems together.  You should make it your
d81 1
a81 1
make a simpset, or added to an existing simpset using {\tt ++}.
d124 1
a124 1
- SIMP_CONV bool_ss [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS]
d147 1
a147 1
  rewriting [1; 2; 4] = [1; 2; 3] with
d150 1
a150 1
  rewriting [2; 4] = [2; 3] with
d153 1
a153 1
  rewriting [4] = [3] with
d167 1
a167 1

d172 1
a172 2
\begin{boxed}
\begin{verbatim}
a174 1
   val CONG_ss : ssdat
d182 1
a182 2
\end{verbatim}
\end{boxed}
d184 53
a236 53
\item[{\tt BOOL\_ss}] The basic rewrites normally used with {\tt
    REWRITE\_TAC []} plus automatic beta conversion, and a couple of
  other trivial theorems that should have been in the basic rewrites
  anyway.

\item[{\tt COMBIN\_ss}] Standard theorems about K, S, I, o from the
  ``combin'' theory.

\item[{\tt CONG\_ss}] Contains two very useful congruences, that
  support contextual reasoning in the presence of implications and
  conditional expressions.  This ``simpset fragment'' combines with
  {\tt BOOL\_ss} to make the {\tt bool\_ss} simpset.

\item[{\tt LIST\_ss}] The most useful rewrites from the ``list''
  library.  Will reduce {\tt MAP}, {\tt APPEND}, {\tt EVERY} and so
  on, where they are applied to concrete lists.  This also includes
  rewrites from the ``List'' library, if this theory is one of the
  current theory's ancestors.

\item[{\tt SUM\_ss}] The useful rewrites from the ``sum'' theory,
  including conditional rewrites for {\tt INR} and {\tt OUTR}.

\item[{\tt NOT\_ss}] Rewrites for pushing negations inward, and for
  simplifying disjunctions involving negations.

\item[{\tt PAIR\_ss}] The useful rewrites from the core ``pair''
  theory.

\item[{\tt UNWIND\_ss}] Contains {\tt UNWIND\_FORALL\_CONV} and {\tt
    UNWIND\_EXISTS\_CONV} for eliminating trivial universal and
  existential quantifications.

\item[{\tt SATISFY\_ss}] Does one-level (non-searching) prolog style
  unification to help eliminate obvious existential quantifiers.  This
  is useful to help guess unknowns in side conditions.

\item[{\tt ARITH\_ss}] This is the most powerful of the built in
  simpset fragments.  It has the following features:
  \begin{itemize}
  \item {\tt ARITH} is applied as a decision procedure
    on all propositions that it may solve.
  \item This application of {\tt ARITH} is ``context-aware'', in the
    sense that any context from the assumption list (when using {\tt
      ASM\_SIMP\_TAC}) or that has been collected via congruence rules
    (e.g from the left-hand-side of an implication) which is
    arithmetic is given to {\tt ARITH\_CONV} as well.
  \item {\tt ARITH} is also used to collect linear like-terms together
    within formulae.  This is implemented via first symbolically
    evaluating the formulae with an ML calculator, then using {\tt
      ARITH\_CONV} to prove that the original formula equals this
    result.
  \item Calls to {\tt ARITH} are cached.
  \end{itemize}
d248 2
a249 4
{\tt bool\_ss} contains {\tt BOOL\_ss} and {\tt CONG\_ss}.  Using
it is akin to using {\tt REWRITE\_TAC}, except that contextual
rewriting using congruence rules for implications and conditional
expressions is also performed.
d270 1
a270 1
sets both the solver and the depther to be \ml{SIMP\_CONV} itself.
d283 1
a283 1
\ml{SIMP\_PROVE} invokes \ml{SIMP\_CONV} and then strips off the
d314 1
a314 1
                          PAIR_ss, UNWIND_ss, SATISFY_ss];
d359 1
a359 1
provided as input to the `plain' rewriter
d379 1
a379 1
like this automatically will almost certainly
d385 1
a385 1
theorem is
d396 1
a396 1
\begin{hol} \begin{verbatim}
d409 1
a409 1
converting \ml{|- $t$} to \ml{|- $t$ = T}.
d412 1
a412 1
before being added to a simpset.  The rewrite maker is
d426 1
a426 1
       |- ... ==> ~t becomes
d433 1
a433 1
       |- ... ==> !x. t becomes
d436 1
a436 1

d441 1
a441 1
       |- ... ==> x becomes
d444 1
a444 1

d447 1
a447 1
    become existentially quantified.  Thus
d465 2
a466 2
fashion.
    \item At each subterm, the simplifier attempts to match
d470 1
a470 1
non-matches.
d475 1
a475 1
the process continues on the new term.
d494 1
a494 1
this example the variable $P$ will be instantiated to
d510 1
a510 1
The limited higher order matching used in the simplifier
d517 1
a517 1
matching.  Note, however, that the simplifier
d540 1
a540 1
fact that, when reducing certain subterms, it is desirable
d559 1
a559 1
As an example, consider the goal
d564 1
a564 1
in the primitive \HOL\ system.
d575 1
a575 1
- SIMP_PROVE hol_ss [CONS_11]
d595 1
a595 1
simple solution of only applying these rewrites when the term
d597 1
a597 1
ordering.
d604 1
a604 1
               (PUPDATE (x1,y1) (PUPDATE (x2,y2) f) =
d616 1
a616 1
To enable AC ordered rewriting,
d619 1
a619 1
simpset by making a \ml{ssdata} object and merging it with
d629 1
a629 1
\ml{ADD\_COMM}.
d694 1
a694 1
a term.  The example we shall use is \ml{ARITH},
d703 1
a703 1
rewrite rules are performed before trying the
d705 1
a705 1
decision procedures are invoked for every reducible subterm.
d707 1
a707 1
See the examples in the source code for how
d726 1
a726 1
critical congruence rules such as those for equality).
d744 2
a745 2
in the first place.  The simplifier only accepts
congruence rules formulated in a certain way.
d754 1
a754 1
the template is \ml{(--`$g$ => $t$ | $e$`--)}.
d805 1
a805 1
prone to several major problems.
d846 1
a846 1
Conditional rewriting allows a limited degree of search when
d860 1
a860 1
When faced with a choice of two rewrite rules, both of which are
d870 1
a870 1
on term rewriting system and their properties such as
d881 1
a881 1
Consider the following potential rewrite rule, taken from
d892 1
a892 1
The problem with such a rewrite rule is that the pattern
d900 1
a900 1
       (PROD (G,prod) (PROD (G,prod) x y) z =
d944 1
a944 1
val summ_DEF = new_recursive_definition {
d946 3
a948 3
        (summ f (SUC n) = f n + summ f n)`--),
    fixity=Prefix,
    name="summ_DEF",
d962 1
a962 1

d971 1
a971 1
(* here's an example of using SIMP_TAC several times along with
d974 2
a975 2
    val thm = SIMP_PROVE hol_ss []
        (--`(n < m) ==> ((m + 1) - n = SUC (m - n))`--)
d980 1
a980 1
     SIMP_TAC bool_ss [thm, summ_DEF] THEN
d1003 1
a1003 1
       ASM_CASES_TAC (--`n=0`--) THEN
d1008 1
a1008 1
(*-------------------------------------------------------------------------
@


1.1.2.6.2.4
log
@Added a credit for me as well as Myra.  I had thought I was going to be
adding an interface to the creation of convdata's as well, but this
turns out to be unnecessary.
@
text
@d4 3
a6 3
\title{A Simplifier/Programmable Grinder for hol90} \author{Donald
  Syme\thanks{Myra VanInwegen and Michael Norrish provided additional
    material.}}
@
