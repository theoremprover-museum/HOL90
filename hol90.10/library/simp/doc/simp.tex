\documentstyle[a4]{article}
\bibliographystyle{plain}

\title{A Simplifier/Programmable Grinder for hol90} \author{Donald
  Syme\thanks{Myra VanInwegen and Michael Norrish provided additional
    material.}}

% ask Don how to fix the code so that people don't have to say
% ``infix ++''

\include{commands}

\begin{document}
\maketitle
% \tableofcontents

This chapter describes `simplification', which is a
powerful new proof technique available in the latest version
of \HOL.

First a word of warning! As always, {\em the more you know about what
  an automated tool can do for you, the more effective it will be for
  you}. Users should ensure they have a good understanding of what
simplification is before they make large sale use of it in their
proofs.  This will help avoid the plethora of problems that develop
from the misapplication of automated tools.

In particular, users new to theorem proving systems should probably
use simplification sparingly, until they have a thorough understanding
of the basics of how a theorem proving system works.

This simplifier is capable of doing a lot.  However this also means it
is difficult to know exactly what it is doing, or why it stops
working.  Because of this, extensive tracing is possible.

This simplifier is based loosely on the Isabelle simplifier.  The
original motivation for doing this work was that I was inspired by
reading the Isabelle reference manual (chapter 10) and wanted to see
how easy such a simplifier would be to implement in \HOL.

\section{What is Simplification?}

In its basic form, simplification is a more general
kind of rewriting. Like rewriting, simplification
starts with some term, say $t_1$, and repeatedly applies
a collection of {\it reduction rules} to the term and its
subterms until no more reductions apply.  This produces
the theorem \ml{|- $t_1$ = $t_2$}, which can be utilised
in various ways.

Simplification is only concerned with the case where the reduction
rules prove that the term $t_1$ is {\it equal} to another term
$t_2$.  Thus the domain of operation of simplification is
most of what is encompassed by {\it equational reasoning}.
Simplification can be generalised to reduction under preorders, but
for the moment we need only be concerned with the equality case.

\section{Simpsets}

The simplifier needs data to work with.  This is specified in
{\em simpsets}. Simpsets are an extremely useful way to organise
your work and group theorems together.  You should make it your
aim to develop good simpsets as part of your theories.
A simpset contains:
\begin{itemize}
    \item A set of rewrite theorems, some of which may be conditional.
    \item A set of congruence theorems which specify
          contextual rewriting information.
    \item A set of conversions which get applied to relevant terms.
    \item A "rewrite maker" function.
\end{itemize}
Simpsets are created in two steps:
\begin{enumerate}
   \item Fragments of simpsets (usually one per theory) are created
using the functions {\tt SIMPSET} or the shortcut {\tt rewrites}.
   \item The fragments are composed (merged) using {\tt mk\_simpset} to
make a simpset, or added to an existing simpset using {\tt ++}.
\end{enumerate}
This two stage approach makes the implementation of the simplifier far
cleaner.  However, it can be annoying to make large simpsets by
composing smaller fragments when you only want to add a few theorems.
Hence you can use the infix\footnote{At least it is intended that
\ml{++} be infix. Currently it isn't when you start up HOL, so you
must type \ml{infix ++} to make it so.} operator \ml{++} to add
theorems to a simpset.  This is useful when you are developing a
theory.

For example, the following three methods
are equivalent, except that the first two create
a reusable component {\tt SUMM\_ss}.
The example is taken from the longer example at the end of this chapter.
\begin{verbatim}
val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = mk_simpset [HOL_ss, SUMML_ss];

val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = hol_ss ++ SUMML_ss;

val summl_ss = hol_ss ++ rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
\end{verbatim}
In general you should build simpsets which solve/normalise a
particular class of terms rather than rely on creating simpsets on-the-fly.

\section{An example: List Equality}

The following example shows how to add rewrites to an existing simpset
and apply the simpset to prove simple results.  The simpset is made up
of simple rewrites about lists, added to the basic reasoning
facilities in {\tt bool\_ss}.  The final line indicates that these
rewrites are actually already present in the built-in simpset {\tt
hol\_ss}, which should be your default starting point when creating
new simpsets.  {\tt hol\_ss} contains powerful arithmetic reasoning
simplification strategies.
\begin{boxed} \begin{verbatim}
- add_theory_to_sml "list";
...
- CONS_11;
val it = |- !h h' t t'. (CONS h t = CONS h' t') = (h = h')

- SIMP_CONV bool_ss [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS]
  ``[1;2;3] = [1;2;3]``;
val it = |- ([1;2;3] = [1;2;3]) = T : thm

- SIMP_CONV bool_ss [CONS_11,NOT_CONS_NIL,NOT_NIL_CONS] ``[x;y] = [1;2]``;
val it = |- ([x; y] = [1; 2]) = (x = 1) /\ (y = 2) : thm

- val silly_ss = bool_ss ++ rewrites [CONS_11, NOT_CONS_NIL, NOT_NIL_CONS];
val silly_ss = - : simpset

- SIMP_CONV silly_ss [] ``[x;y] = [1;2]``;
val it = |- ([x; y] = [1; 2]) = (x = 1) /\ (y = 2) : thm

- SIMP_PROVE hol_ss [] ``~([1;2;4] = [1;2;3])``;
val it = |- ~[1;2;4] = [1;2;3] : thm

\end{verbatim} \end{boxed}
Here is the trace produced when tracing is turned on at a low level:
\begin{boxed} \begin{verbatim}
- open Trace;
- trace_level := 1;;

-  SIMP_PROVE hol_ss [] ``~([1;2;4] = [1;2;3])``;
  rewriting [1; 2; 4] = [1; 2; 3] with
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  rewriting 1 = 1 with |- (x = x) = T
  rewriting [2; 4] = [2; 3] with
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  rewriting 2 = 2 with |- (x = x) = T
  rewriting [4] = [3] with
    |- (CONS h t = CONS h' t') = (h = h') /\ (t = t')
  4 = 3 via cache hit! simplifies to: F
  rewriting [] = [] with |- (x = x) = T
  rewriting F /\ T with |- F /\ t = F
  rewriting T /\ F with |- T /\ t = t
  rewriting T /\ F with |- T /\ t = t
  rewriting ~F with |- ~F = T
val it = |- ~([1; 2; 4] = [1; 2; 3]) : thm
\end{verbatim} \end{boxed}


\section{Built In Simpsets}


Several powerful simpset fragments are included with the core system.
These are based on existing HOL theories.  They can
automate a large amount of ``trivial reasoning'' about
HOL constructs that previously needed special treatment.
\begin{boxed}
\begin{verbatim}
   val BOOL_ss : ssdata
   val COMBIN_ss : ssdata
   val CONG_ss : ssdat
   val LIST_ss : ssdata
   val SUM_ss : ssdata
   val NOT_ss : ssdata
   val PAIR_ss : ssdata
   val UNWIND_ss : ssdata
   val SATISFY_ss : ssdata
   val ARITH_ss : ssdata
\end{verbatim}
\end{boxed}
\begin{description}
\item[{\tt BOOL\_ss}] The basic rewrites normally used with {\tt
    REWRITE\_TAC []} plus automatic beta conversion, and a couple of
  other trivial theorems that should have been in the basic rewrites
  anyway.

\item[{\tt COMBIN\_ss}] Standard theorems about K, S, I, o from the
  ``combin'' theory.

\item[{\tt CONG\_ss}] Contains two very useful congruences, that
  support contextual reasoning in the presence of implications and
  conditional expressions.  This ``simpset fragment'' combines with
  {\tt BOOL\_ss} to make the {\tt bool\_ss} simpset.

\item[{\tt LIST\_ss}] The most useful rewrites from the ``list''
  library.  Will reduce {\tt MAP}, {\tt APPEND}, {\tt EVERY} and so
  on, where they are applied to concrete lists.  This also includes
  rewrites from the ``List'' library, if this theory is one of the
  current theory's ancestors.

\item[{\tt SUM\_ss}] The useful rewrites from the ``sum'' theory,
  including conditional rewrites for {\tt INR} and {\tt OUTR}.

\item[{\tt NOT\_ss}] Rewrites for pushing negations inward, and for
  simplifying disjunctions involving negations.

\item[{\tt PAIR\_ss}] The useful rewrites from the core ``pair''
  theory.

\item[{\tt UNWIND\_ss}] Contains {\tt UNWIND\_FORALL\_CONV} and {\tt
    UNWIND\_EXISTS\_CONV} for eliminating trivial universal and
  existential quantifications.

\item[{\tt SATISFY\_ss}] Does one-level (non-searching) prolog style
  unification to help eliminate obvious existential quantifiers.  This
  is useful to help guess unknowns in side conditions.

\item[{\tt ARITH\_ss}] This is the most powerful of the built in
  simpset fragments.  It has the following features:
  \begin{itemize}
  \item {\tt ARITH} is applied as a decision procedure
    on all propositions that it may solve.
  \item This application of {\tt ARITH} is ``context-aware'', in the
    sense that any context from the assumption list (when using {\tt
      ASM\_SIMP\_TAC}) or that has been collected via congruence rules
    (e.g from the left-hand-side of an implication) which is
    arithmetic is given to {\tt ARITH\_CONV} as well.
  \item {\tt ARITH} is also used to collect linear like-terms together
    within formulae.  This is implemented via first symbolically
    evaluating the formulae with an ML calculator, then using {\tt
      ARITH\_CONV} to prove that the original formula equals this
    result.
  \item Calls to {\tt ARITH} are cached.
  \end{itemize}
\end{description}


All of the above objects are {\em simpset fragments}, not simpsets.
Two actual simpsets are premade from these:
\begin{boxed} \begin{verbatim}
   val hol_ss : simpset
   val bool_ss : simpset
\end{verbatim} \end{boxed}
{\tt hol\_ss} is made by combining all of the simpset fragments listed above.  This
is what most users will initially use.
{\tt bool\_ss} contains {\tt BOOL\_ss} and {\tt CONG\_ss}.  Using
it is akin to using {\tt REWRITE\_TAC}, except that contextual
rewriting using congruence rules for implications and conditional
expressions is also performed.


\section{The Simplification Functions}

The basic routines used to invoke simplification are:
\begin{boxed} \begin{verbatim}
    val SIMP_CONV : simpset -> thm list -> conv
    val SIMP_PROVE : simpset -> thm list -> term -> thm
    val SIMP_RULE : simpset -> thm list -> thm -> thm
    val SIMP_TAC : simpset -> thm list -> tactic
    val ASM_SIMP_TAC : simpset -> thm list -> tactic
    val FULL_SIMP_TAC : simpset -> thm list -> tactic
\end{verbatim} \end{boxed}

In the examples below the theorems and definitions come from the
theories ``List'' and ``arithmetic'' except where noted.

\ml{SIMP\_CONV} makes a simplification conversion from the given
simpset.  The theorems in the second argument are used as additional
rewrites. The conversion uses a top-depth strategy for rewriting. It
sets both the solver and the depther to be \ml{SIMP\_CONV} itself.
\ml{SIMP\_CONV} never fails, though it may diverge.  Beware of
divergence when trying to solve conditions to conditional rewrites.
Examples of its use are:
\begin{verbatim}
- SIMP_CONV hol_ss [] (--`TL[SUC 0;1 + 4; 2 * (3 + 2) + m]`--);
val it = |- TL [SUC 0; 1 + 4; 2 * (3 + 2) + m] = [5; m + 10] : thm
- SIMP_CONV hol_ss [LEFT_ADD_DISTRIB] (--`2 * (b + c) + a`--);
val it = |- 2 * (b + c) + a = a + 2 * b + 2 * c : thm
- SIMP_CONV hol_ss [] (--`(b + c + a) + d = (a + b) + (c + d)`--);
val it = |- ((b + c + a) + d = (a + b) + c + d) = T : thm
\end{verbatim}

\ml{SIMP\_PROVE} invokes \ml{SIMP\_CONV} and then strips off the
\ml{= T} at the end of the theorem. For example:
\begin{verbatim}
- SIMP_PROVE hol_ss [] (--`(b + c + a) + d = (a + b) + (c + d)`--);
val it = |- (b + c + a) + d = (a + b) + c + d : thm
- SIMP_PROVE hol_ss [] (--`!m n p. (p + m = p + n) = (m = n)`--);
val it = |- !m n p. (p + m = p + n) = m = n : thm
\end{verbatim}

\ml{SIMP\_RULE} invokes \ml{CONV\_RULE} with the conversion generated
by \ml{SIMP\_CONV} using the given simpset and additional rewrites. For
example:
\begin{verbatim}
- val th = SPEC (--`CONS (h:'a) t`--) LENGTH_BUTLAST;
val th =
  |- ~(CONS h t = []) ==>
     (LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH (CONS h t))) : thm
- SIMP_RULE hol_ss [] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH t + 1) : thm
\end{verbatim}
Now, we would like to end up with \ml{LENGTH t} on the right hand side
instead of \ml{PRE (LENGTH t + 1)}. We could try the following:
\begin{verbatim}
- SIMP_RULE hol_ss [PRE] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = PRE (LENGTH t + 1) : thm
\end{verbatim}
However, this doesn't work: the rules in \ml{hol\_ss} rewrite \ml{SUC n} to
\ml{n + 1}, and \ml{PRE} only works on \ml{SUC n}. One solution is to
create a simpset that doesn't include the arithmetic simplification:
\begin{verbatim}
val list_ss = mk_simpset [BOOL_ss, COMBIN_ss, LIST_ss, SUM_ss, NOT_ss,
                          PAIR_ss, UNWIND_ss, SATISFY_ss];
= val list_ss = - : simpset
- SIMP_RULE list_ss [PRE] th;
val it = |- LENGTH (BUTLAST (CONS h t)) = LENGTH t : thm
\end{verbatim}

\ml{SIMP\_TAC} makes a simplification tactic from the given simpset
and additional rewrite theorems. The tactic uses a top-depth strategy
for rewriting, and will be recursively reapplied when a simplification
step makes a change. Basically, it invokes \ml{CONV\_TAC} with the
conversion generated by \ml{SIMP\_CONV} using the given simpset and
additional rewrites. Here is an example of using \ml{SIMP\_TAC} (the
definitions are given below in Section \ref{extended-example}):
\begin{verbatim}
- set_goal ([], --`!f n. (SUMM f n n = f n)`--);
val it =
  Status: 1 proof.
  1. Incomplete:
       Initial goal:
       ``!f n. SUMM f n n = f n``
   : proofs
- e (SIMP_TAC hol_ss [summ_DEF,SUMM_DEF]);
OK..
1 subgoal:
val it =
  ``!f n. summ (\k. f (k + n)) 1 = f n``
   : goalstack
\end{verbatim}

\ml{ASM\_SIMP\_TAC} takes the terms in the assumption list,
\ml{ASSUME}s them, and adds them to the list of theorems used for
rewriting. The assumptions are also added to the context that will be
passed to conversions.

\ml{FULL\_SIMP\_TAC} simplifies the assumptions one by one, before
simplifying the goal.  The assumptions are simplified in the order
that they are found in the assumption list, and the simplification
of each assumption is used when simplifying the next assumption.

\section{Rewrite Rules}

\label{rewrite-rules}

Rewrite rules are theorems which express an equality.  They
are similar to the theorems
provided as input to the `plain' rewriter
\ml{REWRITE\_TAC}.  Some examples are:
\begin{hol}\begin{verbatim}
   |- !i j k. (i + j) + k = i + (j + k)
   |- HD (CONS h t) = h
   |- NULL [] = T
   |- (!x. t) = t
\end{verbatim}\end{hol}
In each of the rules above, an infinite number of potential
reductions has been specified.  For example the first rule
will act on any term which matches \ml{(--`($i$ + $j$) + $k$`--)}.

Rewrite rules may also be {\em conditional}.  For example:
\begin{hol}\begin{verbatim}
EL_CONS |- n > 0 ==> (EL n (CONS h t) = EL (n-1) t)
\end{verbatim}\end{hol}
This
rule applies to any term which matches \ml{(--`EL $n$ (CONS $h$ $t$)`--)},
and will only be applied if the condition \ml{(--`$n$ > 0`--)} can be
solved for a particular $n$.  Note that solving an arithmetic side condition
like this automatically will almost certainly
require a decision procedure to be present.

A bit of care has to be taken when formulating conditional rewrites.
For example, say we want to use the fact that the function {\tt MAP2}
preserves the length of lists. One possible way to phrasing the
theorem is
\begin{hol} \begin{verbatim}
MY_LENGTH_MAP2 |- !f m l1 l2. (LENGTH l1 = m) /\ (LENGTH l2 = m) ==>
                  (LENGTH (MAP2 f l1 l2) = m)
\end{verbatim} \end{hol}

However, this will not work as a congruence rule. In a proper rewrite
rule, the variables in the right hand side of the consequent must be
contained in the variables on the left hand side. It is not sufficient
that the values can be determined by the conditions. Thus the rule
must be reformulated, for example as:
\begin{hol} \begin{verbatim}
LENGTH_MAP2 |- !l1 l2.
               (LENGTH l1 = LENGTH l2) ==>
               (!f. (LENGTH (MAP2 f l1 l2) = LENGTH l1) /\
                    (LENGTH (MAP2 f l1 l2) = LENGTH l2))
\end{verbatim} \end{hol}


\subsection{How rewrite rules are made}

Strictly speaking, each reduction rule in a simpset must specify an
equality. However, any theorem which is not already an
equality can be turned into a rewrite rule by simply
converting \ml{|- $t$} to \ml{|- $t$ = T}.
In fact, the process is a little more complex than this.
All theorems are processed by a {\em rewrite maker}
before being added to a simpset.  The rewrite maker is
an attribute of the simpset.  The default rewrite maker
performs the following transformations repeatedly:
\begin{itemize}
    \item A conjunction in the final conclusion lead to
    two reduction rules.  Thus
\begin{hol} \begin{verbatim}
       |- ... ==> x /\ y becomes
       |- ... ==> x and
       |- ... ==> y.
\end{verbatim} \end{hol}

    \item Negations \ml{~$t$} in the final conclusion become \ml{$t$ = F}:
    \begin{hol} \begin{verbatim}
       |- ... ==> ~t becomes
       |- ... ==> (t = F).
\end{verbatim} \end{hol}

    \item Universal quantifiers get stripped off the
    conclusion:
    \begin{hol} \begin{verbatim}
       |- ... ==> !x. t becomes
       |- ... ==> t.
\end{verbatim} \end{hol}

    \item Ignoring conditions, a rewrite rule whose conclusion
    is not an equality, universal quantification,
    negation or conjunction becomes one rewrite rule:
    \begin{hol} \begin{verbatim}
       |- ... ==> x becomes
       |- ... ==> (x = T).
\end{verbatim} \end{hol}

    \item All side conditions are transformed into a single condition,
    where variables free in the condition but not in the equality
    become existentially quantified.  Thus
    \begin{hol} \begin{verbatim}
       |- IS_TYPE t ==> PROG x t ==> IS_PROG x becomes
       |- (?t. IS_TYPE t /\ PROG x t) ==> (IS_PROG x = T)
\end{verbatim} \end{hol}
\end{itemize}

Note that in general, some decision procedure or external routine must
be contained in the simpset in order to automatically choose an
appropriate value for these existential variables.  Two routines are
provided in {\tt HOL\_ss} to handle this --- \ml{SATISFY} and
\ml{UNWIND\_EXISTS\_CONV}.

\subsection{How rewrite rules are applied}

Simplification works by:
\begin{itemize}
    \item Descending the target term in a top-down
fashion.
    \item At each subterm, the simplifier attempts to match
the current subterm with one of the rewrite
rules from the simpset.  This is done
efficiently by using term nets to eliminate most
non-matches.
    \item When a match is found, the simplifier attempts
to solve the conditions to the rewrite rule.  It does this
by trying to simplify the conditions to the term \verb%"T"%.
    \item If the conditions are solved, then the rewrite rule is applied and
the process continues on the new term.
\end{itemize}

This is a somewhat simplified view of things - the exact term traversal
performed is dictated by the congruence rules being used - this is
explained further in Section~\ref{congruence-rules}.


\subsection{Matching and Higher Order Matching}

For a rewrite rule \ml{|- $c_1$ ==> \ldots ==> $t_1$ = $t_2$},
the simplifier will try to match subterms against $t_1$.  The
matching performed is a limited version of {\it higher order
matching}.  For many rewrite rules this will have no effect.  However,
wherever function valued variables are free in $t_1$, then higher
order matching may come into play.

Higher order matching allows a pattern such as
\ml{(--`!x. P x`--)} to match a term like \ml{(--`(!x. x = 3)`--)}.  In
this example the variable $P$ will be instantiated to
\verb%(--`\x. x = 3`--)%.
Higher order matching allows rewrite rules to be far more expressive.
For example, beta reduction can be expressed as a rewrite rule:
\begin{hol} \begin{verbatim}
   |- (\x. P x) y = P y
\end{verbatim} \end{hol}
Some other common higher order rewrite rules are:
\begin{hol} \begin{verbatim}
   |- ~(!x. P x) = (?x. ~P x)
   |- (!x. P x /\ Q) = (!x. P x) /\ Q
   |- (!x. P x /\ Q x) = (!x. P x) /\ (!x. Q x)
\end{verbatim} \end{hol}
All of the quantifier movement conversions from Section~{quantifier-movement}\
can be implemented using higher order rewrite rules.

The limited higher order matching used in the simplifier
only allows function variables in the match to be parameterised
by variables which are quantified in the pattern.  Thus \ml{(--`P x`--)}
will not match \ml{(--`x = 3`--)}, whereas \ml{(--`?x. P x`--)} will.
This ensures unique unifiers as the unifiers can be made maximal
over these variables.  This
avoids many of the difficulties that arise with full higher order
matching.  Note, however, that the simplifier
is sufficiently programmable to allow
other kinds of matching to be used instead of higher order matching.

The higher order matching routines used by the simplifier are also available
for general use by other derived procedures.  The relevant functions
are in the structure {\tt Ho\_match}.


\section{Contextual Rewriting}

The discussion so far has assumed that the simplifier reduces
a term by traversing its subterms in a simple top-depth fashion.  This
is how `plain rewriting' works in the \HOL\ system.  In
this simple case, reductions
made to subterms are justified by the {\it congruence rules}:
$$\Gamma_1\turn l_1=l_2\qquad\qquad\qquad\Gamma_2\turn r_1=r_2\over
\Gamma\turn l_1\ r_1 = l_2\_r_2$$
$$\Gamma_1\turn t_1=t_2\over
\Gamma\turn (\lquant{x}t_1) = (\lquant{x}t_2)$$
which are in turn implemented by the conversional \ml{SUB\_CONV}.

This process is straight forward to implement, but fails to do justice to the
fact that, when reducing certain subterms, it is desirable
to make use of additional facts which hold
locally.  These `context theorems' can be used
in the rewrite process, or can be provided as extra input to
local calls to decision procedures.

To take a simple yet important example, consider
the case when reducing the term $t_2$ within \ml{(--`$t_1$ ==> $t_2$`--)}.
It is reasonable to expect that an automatic tool can make use of any rewrite
rules that can be derived from $t_1$ when simplifying $t_2$.
In other words, $t_1$ is added to the ``current working context'' when
within $t_2$. \footnote{The notion of context turns out to be an important one
in theorem proving work, and provides one of the
motivations for the Window Inference proof style (see the
\HOL\ window inference library for more details on this).
Simplification can be seen as the fully automated, and thus
less controlled, version of window inference, restricted to the equality
relation.}

As an example, consider the goal
\begin{verbatim}
       (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--)
\end{verbatim}
goal is obviously true, but may require several tactics to solve
in the primitive \HOL\ system.

The key observation is that when reducing the term on the right of the
implication, the ``theorems'' \ml{|- P x} and \ml{|- ~(x = y)} can
be assumed.  During simplification, they are added as
rewrites to the current simpset.  They are also added to the
working context of any co--operating decision procedures, but that
will be described in more detail later.

To see this in practice, try:
\begin{boxed} \begin{verbatim}
- SIMP_PROVE hol_ss [CONS_11]
  (--`P x /\ ~(x = y) ==> ~([1;x;5] = [1;y;5])`--);
val it = |- ~[1;x;5] = [1;y;5] : thm
\end{verbatim} \end{boxed}


\section{Ordered Rewriting}

\label{ordered-rewriting}

It is well known that some rewrite rules cause `plain rewriting'
(i.e. \ml {REWRITE\_TAC}) to loop, for instance:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
INSERT_SYM |- x INSERT (y INSERT s) = y INSERT (x INSERT s)
\end{verbatim} \end{hol}
Both of these are {\em permutative rewrites}, in the sense that
the right hand side is a permutation of the pattern on the left.

For such rewrites, the simplifier uses the common and
simple solution of only applying these rewrites when the term
to which they are being applied is strictly reduced according to a term
ordering.

Ordered rewriting will also work for operations whose
commutative theorems have side
conditions, as for partial functions:
\begin{hol} \begin{verbatim}
PUPDATE_SYM |- ~(x1 = x2) ==>
               (PUPDATE (x1,y1) (PUPDATE (x2,y2) f) =
                PUPDATE (x2,y2) (PUPDATE (x1,y1) f))
\end{verbatim} \end{hol}

\subsection{AC Rewriting}

The \HOL\ simplifier supports AC (associative/commutative) rewriting,
in the style of the Isabelle simplifier.  This will create a
normaliser for repeated applications of an associative/commutative
operator like \ml{+}.\footnote{Note that \HOL\ also includes AC\_CONV
for performing similar operations.}

To enable AC ordered rewriting,
the associativity and commutativity theorems
for the operation must be inserted in a
simpset by making a \ml{ssdata} object and merging it with
an existing simpset.
For example, to enable AC rewriting over \ml{+}:
\begin{hol} \begin{verbatim}
ADD_ASSOC |- x + (y + z) = (x + y) + z
ADD_SYM |- x + y = y + x
\end{verbatim} \end{hol}
must be inserted in to a simpset:\footnote{Note that
the theorem \ml{ADD\_SYM} is misnamed in \HOL.  It refers
to the commutativity of addition, and so should be called
\ml{ADD\_COMM}.
Symmetry is a notion
that should only be used for relations such as \verb!=!.}
\begin{boxed} \begin{verbatim}
- val ac_ss = pure_ss ++ SIMPSET {ac =[(ADD_ASSOC,ADD_SYM)],
                                  convs=[],dprocs=[],filter=NONE,rewrs=[],
                                  congs=[]};

- SIMP_CONV ac_ss ``(y + x) + 3 + 6 + (2 * x + 1)``;
val it = |- (y + x) + 3 + 6 + (2 * x + 1) =
            1 + 3 + 6 + y + x + 2 * x : thm

- SIMP_CONV ac_ss ``x + 3 + y + 2 * x + 6 + 1``;
val it = |- x + 3 + y + 2 * x + 6 + 1 =
            1 + 3 + 6 + y + x + 2 * x : thm

- SIMP_PROVE ac_ss ``(y + x) + 3 + 6 + (2 * x + 1) =
                           x + 3 + y + 2 * x + 6 + 1``;
val it = |- (y + x) + 3 + 6 + (2 * x + 1) =
            x + 3 + y + 2 * x + 6 + 1 : thm
\end{verbatim} \end{boxed}


This is implemented using ordered rewriting, with a term ordering that
is AC compatible.    Three
rewrite rules are needed to implement AC rewriting:
\begin{hol} \begin{verbatim}
ADD_SYM |- x + y = y + x
GSYM ADD_ASSOC |- (x + y) + z = x + (y + z)
ADD_LCOMM |- x + (y + z) = y + (x + z)
\end{verbatim} \end{hol}
The simplifier derives the third of these from the first two.
Also, note that the standard form for \HOL\ associativity theorems is the
wrong way round for the purposes of normalising AC nestings to
the right --- the simplifier reverses this automatically.


\section{Tracing}

Simplification often involves many, many inferences, and complex
paths of deduction may occur, leading to almost magical results.
There is a down side to this - simplification is difficult
to understand, and even more difficult to debug when things
go wrong.

The value provided to control tracing is:
\begin{boxed} \begin{verbatim}
   val Trace.trace_level : int ref
\end{verbatim} \end{boxed}
The trace levels currently range from 0 to 5, where level
0 is no tracing and level 5 presents enormous quantities of information.
The aim has been to make trace level 1 produce sufficient information
to debug most problems.  Trace levels 3 to 5 should only be needed
when debugging the simplifier itself.



\section{Decision Procedures and Simplification}

It is exceptionally useful to allow the integration
{\it decision procedures} with the simplification process,
particularly arithmetic decision procedures.

In the context of this discussion, a decision procedure is a function which
performs complex computation before producing a reduction for
a term.  The example we shall use is \ml{ARITH},
which determines the truth of linear
arithmetic formulae over the natural numbers.
It is easy to imagine decision procedures for other
domains such as the integer and real numbers.

Decision procedures are integrated into the simplification
process by adding them to simpsets.  They get
invoked at low priority, in the sense that all reductions via
rewrite rules are performed before trying the
procedure on a term.  All
decision procedures are invoked for every reducible subterm.

See the examples in the source code for how
to add a decision procedure to a simpset.

\section{Congruence Rules}

\label{congruence-rules}

We now fill in the details of the general
process we have outlined above.  During simplification, facts
get added to the current working context because of the application
of {\em congruence rules}.  The user is encouraged to learn to recognise
when a certain construct allows additional crucial assumptions
to be made when simplifying subterms, and to learn how
to express this fact by a congruence rule.

Congruence rules are contained within simpsets.  User congruence
rules are usually theorems, although congruence rules may also
be ML functions (these are potentially useful for infinite families
of congruence rules, and are used for highly speed
critical congruence rules such as those for equality).


\subsection{Constructing Congruence Rules}

Some sample congruence rules are:
\begin{hol} \begin{verbatim}
COND_CONG |- (g = g') ==>
             (g'  ==> (t = t')) ==>
             (~g' ==> (e = e')) ==>
             ((g => t | e) = (g' => t' | e'))

RES_FORALL_CONG |- (R = R') ==>
                   (!x. R' x ==> (P x = P' x)) ==>
                   ((!x::R. P x) = (!x::R'. P' x))
\end{verbatim} \end{hol}
These theorems are not hard to prove.
The principal difficulty is in {\it formulating} the rules
in the first place.  The simplifier only accepts
congruence rules formulated in a certain way.
We shall examine the process of formulating
the first congruence rule in some detail.

The purpose of a congruence rule is to state how
a certain construct is simplified by simplifying its
subterms.  The place to begin is with a `template'
of the construct to be simplified.  In this
case we are interested in simplifying conditionals, thus
the template is \ml{(--`$g$ => $t$ | $e$`--)}.

Next, the final conclusion of the congruence rule
must state that the free subterms $g$, $t$ and $e$ get simplified, and
that the term produced is equal to the term we started with.
Thus the final conclusion is
\begin{hol} \begin{verbatim}
COND_CONG |- ... ==>
             ((g => t | e) = (g' => t' | e'))

\end{verbatim} \end{hol}
Next, the antecedents to this final conclusion specify how these
variables are related.  They are
interpreted as instructions by the simplifier about the order
in which the subterms should be simplified, and what context assumptions may be
made for each subterm.
The first antecedent is simple enough: $g = g'$.  The simplifier
interprets this as ``first starting with $g$, simplify it and get a new
$g'$''.  The second is more complex: \ml{$g'$ ==> ($t$ = $t'$)}.
This is interpreted as ``simplify $t$ to some $t'$, adding the
fact $g'$ to the current context''.  In other words, the antecedent
says that it is valid to assume $g'$ when simplifying $t$.
The third antecedent is similar: \ml{~$g$ ==> ($e$ = $e'$)}.  This
allows the introduction of the context assumption \ml{~$g$}.

After all three antecedents have been processed and discharged by
the simplifier, a theorem {\tt |- ($g$ => $t$ | $e$) = ($g'$ => $t'$ | $e'$}
will have been produced, where the values for $g'$, $t'$ and $e'$ have
been discovered by contextual simplification.  This theorem is
then used by the simplifier to help reduce the entire term.

Putting all this together gives the general congruence rule:
\begin{hol} \begin{verbatim}
COND_CONG |- (g = g') ==>
             (g'  ==> (t = t')) ==>
             (~g' ==> (e = e')) ==>
             ((g => t | e) = (g' => t' | e'))
\end{verbatim} \end{hol}

\subsection{Bad congruence rules}

Ill-formed congruence rules (i.e. congruence rules
not in the form specified above) will cause unpredictable and incorrect
behaviour.  The user should study examples of congruence rules,
consult the relevant manual sections and communicate with other
\HOL\ users should this be a problem.


\section{Avoiding the Pitfalls of Simplification}

Simplification is a powerful theorem proving technique, but is
prone to several major problems.
This section is designed to make the user aware of these in advance!

The pitfalls of simplification can generally be
avoided by two techniques:
\begin{itemize}
   \item Using well designed simpsets.
   \item Using tracing extensively.
\end{itemize}
The behaviour of simplification is almost totally dependent on the
simpset being used.  The user should stop and think about
exactly what reduction behaviour they are specifying when they
group together certain theorems, conversions and decision
procedures.  A well designed simpset will work on a particular
class of problems, and in many cases will do a thorough job
of proving simple facts within that domain.  A poorly
designed simpset constructed by throwing together random
theorems will create all sorts of problems at a later date.

\subsection{Non-termination}

Simplification will continue until no more reductions apply.  It is very
easy to create simpsets which will result in non-termination when
applied to some terms.  \HOL\ detects some simple cases of
non-terminating rewrites (e.g. it doesn't admit rewrites like
\ml{|- x = I x} since the pattern on the left occurs within the
right).  However, there is no general protection against this.
Generally problems arise when two or more theorems interact
to produce looping, such as \ml{|- x > y = y < x} and
\ml{y < x = x > y}.

The best way to avoid non-termination is to ask
the following question about each rewrite you place in a simpset:
{\it Is the rewrite actually contributing toward bringing terms
toward a particular normal form}.  For example, the rewrite
\ml{|- x > y = y < x} should only be added to a simpset if
the normal form we are heading for involves only instances of \ml{<}
for all linear inequalities.

\subsection{Backward Chaining}

Conditional rewriting allows a limited degree of search when
rewriting, since the rewrite is not applied unless all conditions
are solved.  The simplifier itself is used to solve these
conditions.  This will often lead to looping if
theorems which contain the pattern within the conditions
are added as rewrite rules.  The most obvious example is
transitivity theorems:
\begin{hol} \begin{verbatim}
    |- (?z. x < z /\ z < y) ==> x < y
\end{verbatim} \end{hol}
Do not put these theorems into simpsets!

\subsection{Non-confluence}

When faced with a choice of two rewrite rules, both of which are
applicable to a given term, the simplifier will choose
one and ignore the other.  This can lead to {\em confluence}
problems, i.e. it may be that a different final result will
be produced depending on the order in which rewrites are applied.
Non-confluence is mainly a problem for the long term maintainability
of proofs.

Some simpsets may be confluent regardless of the presence of
conflicting rewrite rules.  An extensive literature exists
on term rewriting system and their properties such as
termination and confluence, which the user is encouraged to
study if the subject proves particularly important.

An example of non-confluence is given by the rewrites:
\begin{hol} \begin{verbatim}
<example>
\end{verbatim} \end{hol}

\subsection{Over-applicability}

Consider the following potential rewrite rule, taken from
the underlying theory for the abstract theory of groups:
\begin{hol} \begin{verbatim}
    |- (?G. GROUP (G,prod) /\ G x /\ G y /\ G z) ==>
       (prod (prod x y) z = prod x (prod y z))
\end{verbatim} \end{hol}
The theorem simply states that if $G$ and $prod$ are
together define a algebraic group, then $prod$ is associative.
Note there are no constants apart from \ml{GROUP} --- $G$ and
$prod$ are variables.

The problem with such a rewrite rule is that the pattern
\ml{(--`prod (prod x y) z`--)} will produce many undesirable matches.
The problem is that the rewrite rule is over applicable.  The
best solution at the moment is to make the intent of the rule
more clear, by replacing \ml{(--`prod`--)} with a function
to compute \ml{(--`prod`--)} for a given group:
\begin{hol} \begin{verbatim}
    |- GROUP (G,prod) /\ G x /\ G y /\ G z ==>
       (PROD (G,prod) (PROD (G,prod) x y) z =
        PROD (G,prod) x (PROD (G,prod) y z))
\end{verbatim} \end{hol}
The pattern \ml{(--`PROD (G,prod) (PROD (G,prod) x y) z`--)} will
now be suitably applicable.  The use of \ml{PROD} may seem
redundant, but turns out to be a suitable generalisation.

\section{Summary}

To summarise the main points of this document:
\begin{itemize}
    \item A powerful contextual, conditional simplifier is available
    through the functions \ml{SIMP\_CONV}, \ml{SIMP\_RULE},
    \ml{SIMP\_TAC}, \ml{ASM\_SIMP\_TAC} etc.
    \item Rewrite rules are organised in objects called {\it simpsets}.
    The best simpsets are generally created by making small simpsets and
    combining them with other simpset fragments to form powerful tools.
    \item Rewrite rules are applied using a limited form of higher
    order matching.  Higher order matching allows general theorems about
    functionals such as quantifiers to be applied without the use
    of purpose built conversions.
    \item Simpsets may also contain congruence rules.  Congruence
    rules dictate the term traversal strategy used during simplification
    and the cause the production of context theorems
    \item Simpsets may contain conversions which can act as infinite sets
    of rewrite rules.  This is useful for conversion schemas
    which are essentially reduction but which cannot be formulated
    as rewrite rules (e.g. \ml{REDUCE\_CONV}).
    \item Simpsets may contain decision procedures.  These are invoked
    at lowest priority, and have access to the current working
    context.  The arithmetic decision procedure included with
    \ml{arith\_ss} is an example of the use of this.
\end{itemize}

\section{An extended example}
\label{extended-example}

\begin{verbatim}

new_theory "summ";
infix ++;
open Trace;
trace_level := 1;

val summ_DEF = new_recursive_definition {
    def=(--`(summ f 0 = 0) /\
        (summ f (SUC n) = f n + summ f n)`--),
    fixity=Prefix,
    name="summ_DEF",
    rec_axiom=theorem "prim_rec" "num_Axiom"  };

(* now define the normal notion of summation *)

val SUMM_DEF = new_definition("SUMM_DEF",
    (--`SUMM f n m = summ (\k. f(n+k)) ((m+1)-n)`--));

(* The following is the actual way we want to define this - we could do this *)
(* with TFL.  For now we'll just axiomatise it. *)
val summ = mk_thm([],
    (--`(!f. summ f 0 = 0) /\
        (!f n. n > 0 ==> (summ f n = f 0 + (summ (\k. f (k+1)) (n-1))))`--));


val SUMM_0 = prove((--`!f n m. (n = m + 1) ==> (SUMM f n m = 0)`--),
    SIMP_TAC hol_ss [summ,SUMM_DEF]);
val SUMM_1 = prove((--`!f n m. (n = m) ==> (SUMM f n m = f n)`--),
    SIMP_TAC hol_ss [summ,SUMM_DEF]);
val SUMM_TAKE_LEFT = prove(
    (--`!f n m. (n < m) ==> (SUMM f n m = f n + SUMM f (n+1) m)`--),
    SIMP_TAC hol_ss [SUMM_DEF,summ]);

(* here's an example of using SIMP_TAC several times along with
   small helper theorems *)
local
    val thm = SIMP_PROVE hol_ss []
        (--`(n < m) ==> ((m + 1) - n = SUC (m - n))`--)
in
val SUMM_TAKE_RIGHT = TAC_PROOF
    (([], --`!f n m. (n < m) ==> (SUMM f n m = SUMM f n (m-1) + f m)`--),
     SIMP_TAC hol_ss [SUMM_DEF, summ_DEF] THEN
     SIMP_TAC bool_ss [thm, summ_DEF] THEN
     SIMP_TAC hol_ss [summ_DEF])
end;

(* sum from left - much more efficient as it uses addition not subtraction *)
val SUMML_ss = rewrites [SUMM_TAKE_LEFT, SUMM_1,SUMM_0];
val summl_ss = hol_ss ++ SUMML_ss;

val SUMMR_ss = rewrites [SUMM_TAKE_RIGHT, SUMM_1,SUMM_0];
val summr_ss = hol_ss ++ SUMMR_ss;


(*-------------------------------------------------------------------------
 * SUMM_x = |- !n. n >= 1 ==> (2 * SUMM (\x. x) 1 n = (n + 1) * n) : thm
 *-----------------------------------------------------------------------*)

add_theory_to_sml "arithmetic";

val SUMM_x = prove(
    (--`!n. n >= 1 ==> (2*(SUMM (\x.x) 1 n) = (n + 1) * n)`--),
    INDUCT_TAC
    THENL [
       FULL_SIMP_TAC summr_ss [],
       ASM_CASES_TAC (--`n=0`--) THEN
       ASM_SIMP_TAC summr_ss [LEFT_ADD_DISTRIB,RIGHT_ADD_DISTRIB]
    ]);


(*-------------------------------------------------------------------------
 * Using SIMP_CONV as a calculator for Sums
 *-----------------------------------------------------------------------*)

clear_arith_caches();
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 10`--);
SIMP_CONV summr_ss [] (--`2 * SUMM (\x. x) 1 10`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 15`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 20`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 30`--);
SIMP_CONV summl_ss [] (--`2 * SUMM (\x. x) 1 40`--);


SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 2`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 3`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 4`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 5`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 6`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*x*x) 1 7`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*y*y) 1 3`--);
SIMP_CONV summl_ss [] (--`SUMM (\x. x*y*y) 1 10`--);
\end{verbatim}

\end{document}
